\input{prefix}

\title{\Huge\textbf{{Mathematical modelling in biology}}\\\LARGE Some models}

\author{
  Giacomo Fantoni \\
  \small telegram: \href{https://t.me/GiacomoFantoni}{@GiacomoFantoni} \\[3pt]
  \small Github: \href{https://github.com/giacThePhantom/mathematical-modelling-in-biology}{https://github.com/riacchiappando/mathematical-modelling-in-biology}\\
}


\begin{document}

  \maketitle
  \tableofcontents

\section{The bathtub}
Imagine a container in which there exists an input of water $I(t)$ and an output $O(t)$.
Let $V(t)$ be the volume of water in the bathtub.
The varation in time of the volume of water is:

$$\frac{dV(t)}{dt} = I(t)-O(t)$$

  \subsection{Constant input}
  Assume that the input is constant $I(t) = \Lambda$ and that the output depends on $V(t)$ through a constant $\gamma$.
  The problem then becomes:

  $$\frac{dV(t)}{dt} = \Lambda - \gamma V(t)$$

  This can be solved thorugh the variation of constants method.
  First solve the associated homogeneous equation:

  \begin{align*}
    \frac{du(t)}{dt} = -\gamma u(t)\\
    \frac{du(t)}{u(t)} = -\gamma dt\\
    \int\frac{du(t)}{u(t)} = -\gamma\int dt\\
    \ln(u(t)) = -\gamma t + c\\
    u(t) = e^{-\gamma t + c}\\
    u(t) = Ce^{-\gamma t}\\
  \end{align*}

  Then we can write $V(t) = C(t)e^{-\gamma t}$.
  Computing its derivative:

  $$\frac{dV(t)}{dt} = \frac{dC(t)}{dt}e^{-\gamma t} - \gamma C(t)e^{-\gamma t}$$

  Posing it equal to the starting one:

  \begin{align*}
    \Lambda - \gamma V(t) &= \frac{dC(t)}{dt}e^{-\gamma t} -\gamma C(t)e^{-\gamma t}\\
    \Lambda - \cancel{\gamma V(t)} &= \frac{dC(t)}{dt}e^{-\gamma t} -\cancel{\gamma V(t)}\\
    \frac{dC(t)}{dt} &= \Lambda e^{\gamma t}\\
    C(t) &= \int\Lambda e^{\gamma t}dt\\
    C(t) &= \frac{\Lambda}{\gamma}e^{\gamma t} + c\\
  \end{align*}

  So that the solution then becomes:

  \begin{align*}
    V(t) &= \left[\Lambda\frac{e^{\gamma t}}{\gamma} + c\right]e^{-\gamma t}\\
         &= \frac{\Lambda}{\gamma} + ce^{-\gamma t}\\
  \end{align*}

  The same thing can be done using an integrating factor:

  \begin{align*}
    \frac{dV(t)}{dt} &= \Lambda - \gamma V(t)\\
    \frac{dV(t)}{dt} + \gamma V(t) &= \Lambda\\
    e^{\int \gamma dt}\frac{dV(t)}{dt} + \gamma e^{\int\gamma dt}V(t) &= \Lambda e^{\int\gamma dt}\\
    e^{\gamma t}\frac{dV(t)}{dt} + \gamma e^{\gamma t}V(t) &= \Lambda e^{\gamma t}\\
    \frac{d}{dt}\left[e^{\gamma t}V(t)\right] &= \Lambda e^{\gamma t}\\
    e^{\gamma t}V(t) &= \int\Lambda e^{\gamma t}dt\\
    e^{\gamma t}V(t) &= \frac{\Lambda}{\gamma}e^{\gamma t} + c\\
    V(t) &= \frac{\Lambda}{\gamma} + ce^{-\gamma t}\\
  \end{align*}


  \subsection{Constant input and no output}
  In the case in which there is no output the problem then becomes:

  $$\frac{dV(t)}{dt} = \Lambda$$

  This is easy to solve:

  $$V(t) = \Lambda t + c$$

  \subsection{Varying input}
  Let now the input be a function of time $I(t) = \Lambda(t)$.
  The equation becomes:

  $$\frac{dV(t)}{dt} = \Lambda(t)$$

  The solutions of this is found by integrating both sides:

  $$V(t) + \int_0^t\Lambda(u)du + c$$

  \subsection{Output flux but no input}
  Let now the input be a function of time $O(t) = \gamma V(t)$.
  The variation in time becomes:

  $$\frac{dV(t)}{dt} = -\gamma V(t)$$

  This does not explicitly depends on $t$: it is autonomous.
  This can be solved thourgh the separation of variable methods:

  \begin{align*}
    \frac{dV(t)}{dt} &= -\gamma V(t)\\
    \frac{dV(t)}{V(t)} &= -\gamma dt\\
    \int\frac{dV(t)}{V(t)} &= -\gamma\int dt\\
    \ln(V(t)) &= -\gamma t + c\\
    V(t) &= e^{-\gamma t + c}\\
    V(t) &= e^{-\gamma t}e^c\\
    V(t) &= kre^{-\gamma t}
  \end{align*}

  $k$ in this context is the volume in the bathtub at time $0$, wich could be computed if the volme at time $0$ was given:

  $$\begin{cases}
    \frac{dV(t)}{dt} = -\gamma V(t)\\
    V(0) = V_0
  \end{cases}$$

  So that $V(0)$ can be computed:

  \begin{align*}
    V(0) &= kre^{-\gamma 0}\\
    V(0) &= k
  \end{align*}

\section{Malthus equation}
The Malthus equation is a model for the growth of a population.
It neglets difference amond individuals and migrations.
It represents a population through its size that will increase thru reproduction and decrease through death:

$$\frac{dN(t)}{dt} = B(t) - D(t)$$

The number of births can deaths are linked to the current population.
A death rate $\mu$ can be introduced ($\frac{1}{\mu}$ is the average lifespan) and a birth rate $\beta$ (the average number of newborn generated during a lifespan).
Both are non-negative constants:

\begin{align*}
  \frac{dN(t)}{dt} = \beta N(t) - \mu N(t)\\
  \frac{dN(t)}{dt} = (\beta - \mu)N(t)\\
  \frac{dN(t)}{dt} = rN(t)
\end{align*}

Where $r = \beta-\mu$ is the instanteous growth rate or Malthus parameter or biological potential of the population.
The equation can be solved through the separation of variables method:

\begin{align*}
  \frac{dN(t)}{dt} = rN(t)\\
  \frac{dN(t)}{N(t)} = rdt\\
  \int\frac{1}{N(t)}dN(t) = \int rdt\\
  \ln(N(t)) = rt + c\\
  N(t) = e^{rt + c}\\
  N(t) = ke^{rt}\\
  N(t) = ke^{(\beta-\mu)t}\\
\end{align*}

Where $k$ is the population size at time $0$.
If $r<0$ the population will go extint, while if $r>0$ it will grow exponentially.
If $r=0$ the population is constant.
The basic reproduction number $R_0=\frac{\beta}{\mu}$ can be considered.
$r<0$ is equivalent to $R_0<1$, while $R_0>1$ is equivalent to $r>0$.
Now, the equilibria and stability can be computed:

\begin{align*}
  rN(t) &= 0\\
  N(t) &= 0
\end{align*}

This is the only equilibrium point.

\section{The logistic equation}
The logistic equation introduces into the Malthus' one a term that limits the growth of the population.
The simplest way to do so is to modify the rates, supposing that fertility decreses and mortailtiy inreases inearly with $N(t)$:

\begin{align*}
  \beta(N(t)) = \beta_0 - \tilde{\beta}N(t)\\
  \mu(N(t)) = \mu_0 + \tilde{\mu}N(t)
\end{align*}

Where $\beta_0, \tilde{\beta}, \mu_0, \tilde{\mu}$ are positive constants.
Now the equation becomes:

\begin{align*}
  \frac{dN(t)}{dt} &= \beta(N(t))N(t) - \mu(N(t))N(t)\\
                   &= (\beta_0 - \tilde{\beta}N(t))N(t) - (\mu_0 + \tilde{\mu}N(t))N(t)\\
                   &= \beta_0N(t) - \tilde{\beta}N^2(t) - \mu_0N(t) - \tilde{\mu}N^2(t)\\
                   &= N(t)\left[\beta_0 - \tilde{\beta}N(t) - \mu_0 - \tilde{\mu}N(t)\right]\\
                   &= N(t)\left[(\beta_0 - \mu_0) - (\tilde{\beta} - \tilde{\mu})N(t)\right]\\
                   &= N(t)(\beta_0-\mu_0)\left[1-\frac{N(t)(\tilde{\beta}-\tilde{\mu})}{\beta_0-\mu_0}\right]\\
\end{align*}

Now $(\beta_0-\mu_0) = r$, the Malthus parameter, and $\frac{(\beta_0-\mu_0)}{(\tilde{\beta}-\tilde{\mu})} = K$, the carrying capacity:


$$\frac{dN(t)}{dt} = rN(t)\left[1-\frac{N(t)}{K}\right]$$

If both $\tilde{\beta}$ and $\tilde{\mu}$ are $0$ the equation goes back to the Malthus one.
For very large $N(t)$ and $\tilde{\beta}>0$, the birth rate could go negative.
This does not cause mathamtical problems and the conditions are which it happens do not occur, so it is neglected.
Generally it is assumed that $r>0$, since the population is growing over time.
So if $r>0$, and considering all the other assumptions $K>0$.

  \subsection{Solution}
  To solve the equation we solve for its reciprocal:

  $$u(t) = \frac{1}{N(t)}$$

  This implies that:

  \begin{align*}
    \frac{du(t)}{dt} &= -\frac{1}{N^2(t)}\frac{dN(t)}{dt}\\
                     &= \frac{-rN(t)\left[1-\frac{N(t)}{K}\right]}{N^2(t)}\\
                     &= \frac{-r\left[1-\frac{N(t)}{K}\right]}{N(t)}\\
                     &= -r\left[\frac{1}{N(t)}-\frac{1}{K}\right]\\
                     &= -ru(t) + \frac{r}{K}\\
  \end{align*}

  This is a linear non-homoeneous differential euqation that can be solved with the variation of constants method.
  Solving first the associated homogeneous problem thorugh sepration of variables:

  \begin{align*}
    \frac{du(t)}{dt} &= -ru(t)\\
    \frac{du(t)}{u(t)} &= -rdt\\
    \int\frac{1}{u(t)}du(t) &= \int-rdt\\
    \ln(u(t)) &= -rt + c\\
    u(t) &= e^{-rt+c}\\
    u(t) &= Ce^{-rt}\\
  \end{align*}

  Let $C$ be a function of $t$:

  $$u(t) = C(t)e^{-rt}$$

  And derive it:

  $$\frac{du(t)}{dt} = C'(t)e^{-rt} - rC(t)e^{-rt}$$

  Considering that:

  $$\frac{du(t)}{dt} = -ru(t)+\frac{r}{K}$$

  So that:

  \begin{align*}
    -ru(t) + \frac{r}{K} &= \frac{dC(t)}{dt}e^{-rt} - rC(t)e^{-rt}\\
    -\cancel{rC(t)e^{-rt}}+ \frac{r}{L} &= \frac{dC(t)}{dt}e^{-rt} - \cancel{rC(t)e^{-rt}}\\
    \frac{dC(t)}{dt}e^{-rt} &= \frac{r}{K}\\
    \frac{dC(t)}{dt} &= \frac{r}{K}e^{rt}\\
    C(t) &= \frac{r}{K}\int e^{rt}dt\\
    C(t) &= \frac{\cancel{r}}{K\cancel{r}}e^{rt} + c\\
    C(t) = \frac{1}{K}e^{rt} + c\\
  \end{align*}

  Subsitituting back into $u(t)$:

  \begin{align*}
    u(t) &= \left[\frac{e^{rt}}{K} + c\right]e^{-rt}\\
    u(t) = \frac{1}{K} + ce^{-rt}\\
  \end{align*}

  So that:

  $$N(t) = \frac{1}{\frac{1}{K} + ce^{-rt}}$$

  Now, solving the Cauchy problem where $N(0) = N_0$:

  \begin{align*}
    \frac{1}{\frac{1}{K} + ce^{-r0}} &= N_0\\
    \frac{1}{\frac{N_0}{K} + cN_0} &= 0\\
    \frac{N_0}{K} + cN_0 &= 1\\
    cN_0 &= 1 - \frac{N_0}{K}\\
    c &= \frac{1}{N_0} - \frac{1}{K}\\
  \end{align*}

  So that, substituting:

  \begin{align*}
    N(t) &= \frac{1}{\frac{1}{K} + \left[\frac{1}{N_0} -\frac{1}{K}\right]e^{-rt}}\\
         &= \frac{K}{1 + \left[\frac{K-N_0}{N_0}\right]e^{-rt}}\\
  \end{align*}

  \subsection{Equilibria and stability}
  Assume $r>0$ and $K>0$:

  \begin{align*}
    rN(t)\left[1-\frac{N(t)}{K}\right] &= 0\\
    N(t) = 0\qquad\land\qquad N(t) &= K\\
  \end{align*}

  The first equilibrium is unstable, since the population is growing, while the second is stable.


\section{Logistic equation with periodic carrying capacity}
The logistic model can be modified by assomng that the carrying capacity $K$ is a periodic, always positive function of $t$.
For example:

$$k(t) = K_0(1+\epsilon\cos(\omega t))\qquad\qquad 0<\epsilon< 1$$

The model then becomes:

\begin{align*}
  \frac{dN(t)}{dt} &= rN(t)\left[1-\frac{N(t)}{K(t)}\right]\\
                   &= rN(t)\left[1-\frac{N(t)}{K_0(1+\epsilon\cos(\omega t))}\right]\\
\end{align*}

Which makes the equation not autonomous anymore.

  \subsection{Solution}
  The equation can be solved with the same reciprocal trick:

  $$u(t) = \frac{1}{N(t)}$$

  \begin{align*}
    \frac{du(t)}{dt} &= -\frac{1}{N^2(t)}\frac{dN(t)}{dt}\\
                     &= \frac{-r\cancel{N(t)}\left[1-\frac{N(t)}{K(t)}\right]}{N^{\cancel{2}(t)}}\\
                     &= \frac{-r\left[1-\frac{N(t)}{K(t)}\right]}{N(t)}\\
                     &= -r\left[\frac{1}{N(t)}-\frac{1}{K(t)}\right]\\
                     &= -ru(t) + \frac{r}{K(t)}\\
  \end{align*}

  Now this can be solved with the Variation of constants.
  Solving the associated homogeneous problem:

  $$u(t) = Ce^{-rt}$$

  Now let $C$ a function of $t$ and compute the derivative:

  $$\frac{du(t)}{dt} = \frac{dC(t)}{dt}e^{-rt} - rC(t)e^{-rt}$$

  So now, substituting what we now:

  \begin{align*}
    \frac{dC(t)}{dt}e^{-rt} - rC(t)e^{-rt} = -ru(t) + \frac{r}{K(t)}\\
    \frac{dC(t)}{dt}e^{-rt} - rC(t)e^{-rt} = -ru(t) + \frac{r}{K(t)}\\
    \frac{dC(t)}{dt}e^{-rt} - \cancel{rC(t)e^{-rt}} = -\cancel{rC(t)e^{-rt}} + \frac{r}{K(t)}\\
    \frac{dC(t)}{dt}e^{-rt} = \frac{r}{K(t)}\\
    \frac{dC(t)}{dt} = \frac{r}{K(t)}e^{rt}\\
    C(t) = r\int \frac{e^{rt}}{K(t)}dt\\
    C(t) = r\int \frac{e^{rt}}{K_0(1+\epsilon\cos(\omega t))}dt\\
    C(t) = \frac{r}{K_0}\int \frac{e^{rt}}{1+\epsilon\cos(\omega t)}dt\\
  \end{align*}

  Which has no analyitical solution.
  So now:

  $$u(t) = e^{-rt}\frac{r}{K_0}\int \frac{e^{rt}}{1+\epsilon\cos(\omega t)}dt$$

  And:

  $$N(t) = \frac{e^{rt}K_0}{r\int \frac{e^{rt}}{1+\epsilon\cos(\omega t)}dt}$$

  \subsection{Equilibria}
  Assuming still $r>0$ and $K_0>0$, the equilibria can be computed:

  \begin{align*}
    rN(t)\left[1-\frac{N(t)}{K(t)}\right] &= 0\\
    N(t) = 0\qquad\land\qquad N(t) &= K(t)\\
  \end{align*}

  The first equlibria is unstable.
  The second is an asymptotically stable periodic equilibria with period $T = \frac{2\pi}{\omega}$.

\section{Predator-Prey system}
The predator-prey system is a non-linear system of two differential equations:

$$\begin{cases}
  \frac{dH(t)}{dt} = rH(t)\left[1-\frac{H(t)}{K}\right] - \alpha H(t)P(t)\\
  \frac{dP(t)}{dt} = -\mu P(t) + \gamma\alpha H(t)P(t)\\
\end{cases}$$

Estimating now the parameters:

$$\begin{cases}
  \frac{dH(t)}{dt} = 2H(t)\left[1-H(t)\right] - 2H(t)P(t)\\
  \frac{dP(t)}{dt} = -\frac{1}{2} P(t) + 3H(t)P(t)\\
\end{cases}$$

  \subsection{Equilibrium points}

  \begin{align*}
    \begin{cases}
      2H(t)\left[1-H(t)\right] - 2H(t)P(t) &= 0\\
      -\frac{1}{2} P(t) + 3H(t)P(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) = 0\qquad\land\qquad H(t) &= 1-P(t)\\
      -\frac{1}{2} P(t) + 3H(t)P(t) &= 0\\
    \end{cases}\\
  \end{align*}

  There are two solution for the first equation.
  Considering the first:

  \begin{align*}
    \begin{cases}
      H(t) &= 0\\
      -\frac{1}{2} P(t) + 3H(t)P(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) = 0\\
      -\frac{1}{2} P(t)&= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) = 0\\
      P(t)&= 0\\
    \end{cases}\\
  \end{align*}

  So the first equilibrium point is $E_1 = (0,0)$.\\
  Considering now the second:

  \begin{align*}
    \begin{cases}
      H(t) &= 1-P(t)\\
      -\frac{1}{2} P(t) + 3H(t)P(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) &= 1-P(t)\\
      -\frac{1}{2} P(t) + 3(1-P(t))P(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) &= 1-P(t)\\
      -\frac{1}{2} P(t) + 3P(t) - 3P^2(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) &= 1-P(t)\\
      P(t)\left[-\frac{1}{2} + 3 - 3P(t)\right] &= 0\\
    \end{cases}\\
    \begin{cases}
      H(t) &= 1-P(t)\\
      P(t) &= 0\qquad\land\qquad P(t) = \frac{5}{6}\\
    \end{cases}\\
  \end{align*}

  So there are two equilibrium points: $E_2 = (1,0)$ and $E_3 = \left(\frac{1}{6},\frac{5}{6}\right)$.
  The vector field will be enriched adding the equilibrium points and the null isoclines, the curves where the derivatives are posed equal to zero one at a time:

  \begin{align*}
    2H(t)\left[1-H(t)\right] - 2H(t)P(t) &= 0\\
    H(t) = 0\qquad\land\qquad H(t) &= 1-P(t)\\
  \end{align*}

  And:

  \begin{align*}
    -\frac{1}{2}P(t) + 3H(t)P(t) &= 0\\
    P(t) \left[-\frac{1}{2} + 3H(t)\right] &= 0\\
    P(t) = 0\qquad\land\qquad H(t) = \frac{1}{6}\\
  \end{align*}

  Furhtermore the phase plane will be filled with vectors having components:

  $$[f(H(t),P(t)),g(H(t),P(t))]$$

  Solutions will be tangent to these vectors, although there will not be any information about the evolution in time (there is no $t$ axis).
  The three equilibrium will be consant in time.
  Since now the objective is qualitative it is enouch, instead of evaluating the points, to study the sign of the derivatives in the regions identified by the isoclines.
  In each region the sign will be constant: the isoclines are points in which derivatives change sign, so:

  \begin{align*}
    \frac{dH(t)}{dt} &>0\\
    2H(t)[1-H(t)] - 2H(t)P(t) &>0\\
    2H(t) - 2H^2(t) - 2H(t)P(t) &>0\\
    H(t)[2-2H(t) - 2P(t)] &>0\\
    (H(t) > 0\land 2-2H(t) -2P(t) > 0)\lor(H(t) < 0\land 2-2H(t) -2P(t) < 0) &>0\\
  \end{align*}

  Since the second solution is not comptaible with the biological domain, $\frac{dH(t)}{dt} >0$:

  $$H(t) > 0\land H(t) < 1- P(t)$$

  Now, considering the second equation:

  \begin{align*}
    \frac{dP(t)}{dt} &> 0\\
    -\frac{1}{2}P(t) + 3H(t)P(t) &> 0\\
    P(t)\left[-\frac{1}{2} + 3H(t)\right] &> 0\\
    (P(t) > 0\land -\frac{1}{2}+3H(t) >0)\lor (P(t) < 0\land -\frac{1}{2}+3H(t) <0) &> 0\\
  \end{align*}

  The second solution is again not compatible with the biological domain, $\frac{dP(t)}{dt} >0$:

  $$P(t) > 0\land H(t) >\frac{1}{6}$$

  From this the direction field can be populated with vectors with unitary coordinates and negative horizontal when over the $H(t) + 1-P(t)$ isocline and positive under it.
  Morever vectors to the left of $H(t) = \frac{1}{6}$ wil have negative vertical component and positive to the right.
  All vectors on an isocline will have the corresponding component equal to $0$.
  From this $E_1$ and $E_2$ are unstable, whie it is hard to make predictions about $E_3$.

  \subsection{Stability}
  To compute the stability of the equilibria first the Jaciobian needs to be computed:

  \begin{align*}
    J &= \begin{bmatrix} \frac{\partial f}{\partial H(t)} & \frac{\partial f}{\partial P(t)}\\ \frac{\partial g}{\partial H(t)} & \frac{\partial g}{\partial P(t)} \end{bmatrix}\\
      &=\begin{bmatrix} 2- 4H(t) -2H(t) & -2H(t)\\3P(t) & -\frac{1}{2} + 3H(t)\end{bmatrix}
  \end{align*}

  Now inserting the value of the equilibrium in the Jacobian.
  For $E_1$:

  $$J = \begin{bmatrix}2 & 0\\ 0 & -\frac{1}{2}\end{bmatrix}$$

  It has eigenvalue $\lambda_1 = 2$ and $\lambda_2 = -\frac{1}{2}$, so $S(A)= 2>0$, then this equilibrium is unstable.\\

  For $E_2$:

  $$J = \begin{bmatrix} -2 & -2\\ 0 & \frac{5}{2}\end{bmatrix}$$

  This is a triangular matrix, so it has eigenvalues $\lambda_1 = -2$ and $\lambda_2 = \frac{5}{2}$, so $S(A) = \frac{5}{2} > 0$, then this equilibrium is unstable.\\

  For $E_3$:

  $$J=\begin{bmatrix} -\frac{1}{3} & -\frac{1}{3}\\ \frac{5}{6} & 0\end{bmatrix}$$

  To not compute the eigenvalues the Routh-Hurwitz critera are used.
  It can be computed that $det(A) > 0$ and $tr(A) < 0$, so $S(A) < 0$, then this equilibrium is asymptotically stable.

\section{Epidemiological models}
They are used to simulate the spread of an epidemic across a population.
A simple one is the SIR one, that categorizes the population into:

\begin{multicols}{2}
  \begin{itemize}
    \item $S$: the susceptible: when they come into contact with an infectious individual they contract the disease and transition to the infectious compartment.
    \item $I$: the infectious individuals: they have been infectd and can infect the susceptible.
    \item $R$ the removed (immune) individuals: they have been infected and have recovered, and entered the removed compartment.
  \end{itemize}
\end{multicols}

The compartments are linnked via different rates:

\begin{multicols}{2}
  \begin{itemize}
    \item The birth rate $\mu$ feeds people into $S$, with dynamics that depends on the total number of people $N = S+I+R$.
    \item Natural deaths can occur in all gropups with rate equal to the one of births $\mu$ and with dynamics that depends on the number of people in the compartment.
    \item Infections $S\to I$ happen with a contact rate $\beta$ and are modelled with mass action dynamics.
    \item Infected people recover with a recovery rate $\gamma$, with dynamics that depend n the total number of infecte people.
  \end{itemize}
\end{multicols}

Each SIR variable has the number of people as dimension, while rates $\frac{1}{t}$: the derivatives will have dimenison $\frac{people}{t}$.
The system governing the dynamics is:

$$\begin{cases}
  \frac{dS(t)}{dt} &= -\beta S(t)\frac{I(t)}{N} - \mu S(t) + \mu N\\
  \frac{dI(t)}{dt} &= \beta S(t)\frac{I(t)}{N} - \gamma I(t) - \mu I(t)\\
  \frac{dR(t)}{dt} &= \gamma I(t) - \mu R(t)
\end{cases}$$

Since $N = S(t) + I(t) + R(t)\Rightarrow R(t) = N - S(t) - I(t)$, the system can be rewritten as:

$$\begin{cases}
  \frac{dS(t)}{dt} = -\beta S(t) \frac{I(t)}{N} - \mu S(t) + \mu N\\
  \frac{dI(t)}{dt} = \beta S(t)\frac{I(t)}{N} - \gamma I(t) - \mu I(t)\\
\end{cases}$$

  \subsection{Normalization}
  The system can be modified further by considering the fraction of people in each comparment instead of the total number introducing:

  $$X(t) = \frac{S(t)}{N}\qquad\qquad Y(t) = \frac{I(t)}{N}$$

  Dividing all terms in both equations by $N$.
  It is expected that $0\ge X(t),Y(t)\le 1$.
  Considering the derivatives:

  \begin{align*}
    \frac{dS(t)}{dt}\frac{I(t)}{N} &= \frac{d\frac{S(t)}{N}}{dt}\\
                                 &= \frac{dX(t)}{dt}\\
  \end{align*}

  And:

  \begin{align*}
    \frac{dI(t)}{dt}\frac{I(t)}{N} &= \frac{d\frac{I(t)}{N}}{dt}\\
                                 &= \frac{dY(t)}{dt}\\
  \end{align*}

  So that the normalized system becomes:

  $$\begin{cases}
    \frac{dX(t)}{dt} &= -\beta X(t)Y(t) - \mu X(t) + \mu\\
    \frac{dY(t)}{dt} &= \beta X(t)Y(t) - \gamma Y(t) - \mu Y(t)
  \end{cases}$$

  \subsection{Vaccination rate and temporary immunity}
  It can be assumed that immunity is temporary and people in $R$ can flow back in $S$ with rate $\sigma$, and that there is a vaccination rate $p$ at birth, so that a fraction $p$ of the births is automatically immune and $1-p$ feeds $S$.
  The previous system described the case in which $p=0\land\sigma=0$.
  Now the system becomes:

  $$\begin{cases}
    \frac{dS(t)}{dt} &= -\beta S(t)\frac{I(t)}{N} - \mu S(t) + \mu (1-p)N + \sigma R(t)\\
    \frac{dI(t)}{dt} &= \beta S(t)\frac{I(t)}{N} - \gamma I(t) - \mu I(t)\\
    \frac{dR(t)}{dt} &= \gamma I(t) - \mu R(t) - \sigma R(t) + \mu p N
  \end{cases}$$

  It is still true that $R = N-S-I$, so again the third equation can be not considered:

  $$\begin{cases}
    \frac{dS(t)}{dt} &= -\beta S(t)\frac{I(t)}{N} - \mu S(t) + \mu (1-p)N + \sigma (N - I(t) - S(t)\\
    \frac{dI(t)}{dt} &= \beta S(t)\frac{I(t)}{N} - \gamma I(t) - \mu I(t)\\
  \end{cases}$$

  Then introduce $X(t) = \frac{S(t)}{N}$ and $Y(t) = \frac{I(t)}{N}$ to normalize the system:

  $$\begin{cases}
    \frac{dX(t)}{dt} &= -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t))\\
    \frac{dY(t)}{dt} &= \beta X(t)Y(t) - \gamma Y(t) - \mu Y(t)\\
  \end{cases}$$

  \subsection{Equilibria}
  To find the equilibria let's first put the derivatives equal to zero:

  \begin{align*}
    \begin{cases}
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t)) &= 0\\
      \beta X(t)Y(t) - \gamma Y(t) - \mu Y(t) &= 0\\
    \end{cases}\\
    \begin{cases}
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t)) &= 0\\
      Y(t)(\beta X(t) - \gamma - \mu) &= 0\\
    \end{cases}\\
    \begin{cases}
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t)) &= 0\\
      Y(t) = 0 \land X(t) &= \frac{\gamma+\mu}{\beta}\\
    \end{cases}\\
  \end{align*}

  Discussing first for $Y(t) = 0$:

  \begin{align*}
    \begin{cases}
      Y(t) &= 0\\
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t)) &= 0\\
    \end{cases}\\
    \begin{cases}
      Y(t) &= 0\\
      - \mu X(t) + \mu (1-p) + \sigma (1 - X(t)) &= 0\\
    \end{cases}\\
    \begin{cases}
      Y(t) &= 0\\
      - \mu X(t) + \mu (1-p) + \sigma - \sigma X(t)) &= 0\\
    \end{cases}\\
    \begin{cases}
      Y(t) &= 0\\
      -(\mu +\sigma)X(t) &=- \mu (1-p) - \sigma\\
    \end{cases}\\
    \begin{cases}
      Y(t) &= 0\\
      X(t) &= \frac{\mu (1-p) + \sigma}{\mu+\sigma}\\
    \end{cases}\\
  \end{align*}

  So the first equilibrium, or desease free equilibrium $DFE$ is:

  $$E_1 = DEF = \left(\frac{\mu (1-p) + \sigma}{\mu+\sigma},0\right)$$

  Now discussing for $X(t) = \frac{\gamma+\mu}{\beta}$:

  \begin{align*}
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma (1 - X(t) - Y(t)) &= 0\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      -\beta X(t)Y(t) - \mu X(t) + \mu (1-p) + \sigma - \sigma X(t) - \sigma Y(t)) &= 0\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      (\beta X(t) +\sigma)Y(t) &= - \mu X(t) + \mu (1-p) + \sigma - \sigma X(t)\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      (\beta X(t) +\sigma)Y(t) &= - (\mu+\sigma)X(t) + \mu (1-p) + \sigma\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      Y(t) &= \frac{- (\mu+\sigma)X(t) + \mu (1-p) + \sigma}{(\beta X(t) +\sigma)}\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      Y(t) &= \frac{- (\mu+\sigma)\frac{\gamma+\mu}{\beta} + \mu (1-p) + \sigma}{\left(\cancel{\beta} \frac{\gamma+\mu}{\cancel{\beta}} +\sigma\right)}\\
    \end{cases}\\
    \begin{cases}
      X(t) &= \frac{\gamma+\mu}{\beta}\\
      Y(t) &= \frac{ \mu (1-p) + \sigma- (\mu+\sigma)\frac{\gamma+\mu}{\beta}}{\gamma+\mu +\sigma}\\
    \end{cases}\\
  \end{align*}

  So, the second equilibrium, or endemic equilibrium $EE$ is:

  $$E_2 = EE = \left(\frac{\gamma + \mu}{\beta},\frac{ \mu (1-p) + \sigma- (\mu+\sigma)\frac{\gamma+\mu}{\beta}}{\gamma+\mu +\sigma}\right)$$

  From an epiemiological point of view the quantity $R_0$, the average number of individuals infected by a newly infected individual over all its infecious period:

  $$R_0 = \frac{\beta}{\mu+\gamma}\qquad\qquad\ X = \frac{1}{R_0}$$

  Using $R_0$ the endemic equilibrium can be reformulated:

  $$E_2 = EE = \left(\frac{1}{R_0}, \frac{\mu(1-p)+\sigma-\frac{1}{R_0}(\mu+\sigma)}{\mu+\gamma+\sigma}\right)$$

    \subsubsection{Structuring the equilibria}
    Consider now the case of no vaccination and permanent immunity ($p = 0$, $\sigma = 0$).
    The equilibria now become:

    $$E^*_1 = DFE^* = \left(1,0\right)\qquad\qquad E^*_2 = EE^* = \left(\frac{1}{R_0}, \frac{\mu\left(1-\frac{1}{R_0}\right)}{\mu+\gamma}\right)$$

    While $DFE^*$ is always feasible, $EE^*$ is feasible only if $R_0 > 1$: if not $Y$ will eighter go to zero if $R_0=1$ (which is not compatible with this equilibrium), or it will reach negative numbers if $R_0<1$ (which is not compatible with biology).

  \subsection{Stability}
  To check for the stability of the equilibria, first write the Jacobian matrix:

  $$J = \begin{bmatrix}-\beta Y(t) -\mu -\sigma & \beta X(t) -\sigma\\ \beta Y(t) & \beta X(t) - \gamma - \mu\end{bmatrix}$$

  Then it is evaluated at the equilibria.
  Start with $DFE = \left(\frac{\mu(1-p)+\sigma}{\mu+\sigma},0\right)$:

  $$J_{DFE} = \begin{bmatrix}-\mu -\sigma & -\beta\frac{\mu(1-p)+\sigma}{\mu+\sigma}\\ 0 & \beta\frac{\mu(1-p)+\sigma}{\mu+\sigma}-\gamma-\mu\end{bmatrix}$$

  This is a triangular matrix, so it has eigenvalues:

  \begin{align*}
    \lambda_1 &= -\mu-\sigma\\
    \lambda_2 &= \beta\frac{\mu(1-p)+\sigma}{\mu+\sigma}-\gamma-\mu\\
  \end{align*}

  $\lambda_1$ is always negative, while to discuss $\lambda_2$ introduce:

  $$R_c = \frac{\beta}{\mu+\gamma}\frac{\mu(1-p) +\sigma}{\mu + \sigma} = R_0\frac{\mu(1-p) + \sigma}{\mu+\sigma}$$

  It can be seen that:

  \begin{align*}
    \lambda_2 &= R_c(\mu+\gamma)-\gamma-\mu\\
              &= R_c(\mu+\gamma)-(\gamma+\mu)\\
  \end{align*}

  So that:

  \begin{align*}
    \lambda_2 &>0 \\
    R_c(\mu+\gamma)-(\mu+\gamma) &> 0\\
    R_c &> \frac{\mu+\gamma}{\mu+\gamma}\\
    R_c &> 1\\
  \end{align*}

  The $DFE$ will be unstable if $R_c>1$ ($S(A)$ positive) and asymptotically stable if $R_c < 1$ ($S(A)$ negative).\\
  Now, to discuss the stability of $E_2 = EE = \left(\frac{1}{R_0}, \frac{\mu(1-p) + \sigma - \frac{1}{R_0}(\mu+\sigma)}{\mu+\gamma+\sigma}\right)$.
  Remember that the $EE$ is well defined only if $R_0>1$ and remembering $R_0 = \frac{\beta}{\mu+\gamma}$, the Jacobian will be:

  \begin{align*}
    J &= \begin{bmatrix}-\beta\frac{\mu(1-p) + \sigma - \frac{1}{R_0}(\mu+\sigma)}{\mu + \gamma+ \sigma} -\mu - \sigma & -\beta\frac{1}{R_0}-\sigma\\\beta\frac{\mu(1-p) + \sigma - \frac{1}{R_0}(\mu+\sigma)}{\mu + \gamma+ \sigma} & \beta\frac{1}{R_0} - \gamma - \mu\end{bmatrix}\\
      &= \begin{bmatrix}-\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} -\mu - \sigma & -\beta\frac{\mu+\gamma}{\beta}-\sigma\\\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} & \beta\frac{\mu+\gamma}{\beta} - \gamma - \mu\end{bmatrix}\\
      &= \begin{bmatrix}-\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} -\mu - \sigma & -\mu-\gamma-\sigma\\\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} & \mu+\gamma - \gamma - \mu\end{bmatrix}\\
      &= \begin{bmatrix}-\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} -\mu - \sigma & -\mu-\gamma-\sigma\\\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} & 0\end{bmatrix}\\
  \end{align*}

  To discuss the stability consider the Routh-Hurzwitz criterion for square matrices.
  First consider the trace of the matrix:

  \begin{align*}
    Tr(J) = -\beta\frac{\mu(1-p) + \sigma - \frac{\mu+\gamma}{\beta}(\mu+\sigma)}{\mu + \gamma+ \sigma} -\mu - \sigma + 0 &\overbrace{<}^{?} 0\\
    -\beta\mu +\beta\mu p + \beta\sigma + \cancel{\beta}\frac{\mu+\gamma}{\cancel{\beta}}\mu+\cancel{\beta}\frac{\mu+\gamma}{\cancel{\beta}}\sigma -\mu^2 - \sigma\mu-\gamma\mu - \sigma\mu-\gamma\sigma-\sigma^2 &\overbrace{<}^{?} 0\\
    -\beta\mu +\beta\mu p + \beta\sigma + (\mu+\gamma)\mu+(\mu+\gamma)\sigma -\mu^2 - \sigma\mu-\gamma\mu - \sigma\mu-\gamma\sigma-\sigma^2 &\overbrace{<}^{?} 0\\
    -\beta\mu +\beta\mu p + \beta\sigma + \cancel{\mu^2}+\cancel{\gamma\mu}+\cancel{\mu\sigma}+\cancel{\gamma\sigma} -\cancel{\mu^2} - \cancel{\sigma\mu}-\cancel{\gamma\mu} - \sigma\mu-\cancel{\gamma\sigma}-\sigma^2 &\overbrace{<}^{?} 0\\
    \overbrace{\underbrace{-\beta\mu +\beta\mu p}_{p<1}}^{<0} + \beta\sigma - \sigma\mu-\sigma^2 &\overbrace{<}^{?} 0\\
    Tr(J) &< 0\\
  \end{align*}

  So $Tr(J) < 0$.
  Now consider the determinant.
  For a $2\times 2$ matrix the determinant is: $x_{11}x_{22}-x_{12}x_{21}$.
  From the computation of the trace $x_{11} < 0$ and $x_{22} = 0$, while $x_{21} > 0$ and $x_{12} < 0$.
  So the $det(J) > 0$.
  From this it can be concluded that the Endemic equilibrium $EE$ is asymptotically stable, when it exists.

\section{Enzymatic reactions}
An enzymatic reaction follows:

$$S + E \xrightleftharpoons[k_{-1}]{k_1} ES \xrightarrow{k_2} E + P$$

By assuming a law of mass action dynamics (the rate of each reaction is proportional to the concentration of the reactants), this scheme can be transformed into a set of differential equations.
Let $s = [S]$, $e = [E]$, $c = [SE]$ and $p = [P]$:

$$\begin{cases}
  \frac{ds(t)}{dt} = -k_1s(t)e(t) + k_{-1}c(t)\\
  \frac{de(t)}{dt} = -k_1s(t)e(t) + (k_{-1}+k_2)c(t)\\
  \frac{dc(t)}{dt} = k_1s(t)e(t) - (k_{-1}+k_2)c(t)\\
  \frac{dp(t)}{dt} = k_2c(t)\\
\end{cases}$$

The first three equations do not depend on $p$, so the last equaiton can be excluded as:

$$p(t) = k_2\int_0^tc(s)dt$$

Then the system becomes:

$$\begin{cases}
  \frac{ds(t)}{dt} = -k_1s(t)e(t) + k_{-1}c(t)\\
  \frac{de(t)}{dt} = -k_1s(t)e(t) + (k_{-1}+k_2)c(t)\\
  \frac{dc(t)}{dt} = k_1s(t)e(t) - (k_{-1}+k_2)c(t)\\
\end{cases}$$

Addutionally it can be noted how $\frac{de(t)}{dt} + \frac{dc(t)}{dt} = 0$, meaning that:

$$\frac{d}{dt}[e(t)+c(t)] = 0\rightarrow e(t) + c(t) = k = e_0$$

Given that $\frac{de(t)}{dt}$ can be recovered when $\frac{dc(t)}{dt}$ is known, computing $e(t) = e_0-c(t)$, the second equation can be excluded from the system:

$$\begin{cases}
  \frac{ds(t)}{dt} = k_{-1}c(t)-k_1s(t)(e_0-c(t)) \\
  \frac{dc(t)}{dt} = k_1s(t)(e_0-c(t)) - (k_{-1}+k_2)c(t)\\
\end{cases}$$

Now consider $s(0) = s_0$, $c(0) = 0$ and $p(0) = 0$ and normalize the system by:

$$x(t) = \frac{s(t)}{s_0}\qquad\qquad\land\qquad\qquad y(t) = \frac{c(t)}{e_0}$$

  \subsection{Reactant abundance}
  Assume a negligibly small cocnentration of enzyme:

  $$\epsilon = \frac{e_0}{s_0}\ll 1$$

  Now normalizing the system, note that $\frac{ds(t)}{dt}\to\frac{ds(t)}{dt}\frac{1}{s_0} = \frac{d\frac{s(t)}{s_0}}{dt}$ and $\frac{dc(t)}{dt}\to\frac{dc(t)}{dt}\frac{1}{e_0}=\frac{d\frac{c(t)}{e_0}}{dt}$.
  So that the normalized system:

  \begin{align*}
    \begin{cases}
      s_0\frac{dx(t)}{dt} = k_{-1}y(t)e_0 - k_1x(t)s_0(e_0-y(t)e_0)\\
      e_0\frac{dy(t)}{dt} = k_{1}s_0x(t)(e_0-e_0y(t)) - e_0y(t)(k_{-1}+k_2)\\
    \end{cases}\\
    \begin{cases}
      \frac{dx(t)}{dt} = k_{-1}y(t)\frac{e_0}{s_0} - k_1x(t)s_0\frac{e_0}{s_0}(1-y(t))\\
      \frac{dy(t)}{dt} = k_{1}s_0x(t)(1-y(t)) - y(t)(k_{-1}+k_2)\\
    \end{cases}\\
    \begin{cases}
      \frac{dx(t)}{dt} = k_{-1}y(t)\epsilon - k_1x(t)s_0\epsilon(1-y(t))\\
      \frac{dy(t)}{dt} = k_{1}s_0x(t)(1-y(t)) - y(t)(k_{-1}+k_2)\\
    \end{cases}\\
    \begin{cases}
      \frac{dx(t)}{dt} = \epsilon[k_{-1}y(t) - k_1x(t)s_0(1-y(t))]\\
      \frac{dy(t)}{dt} = k_{1}s_0x(t)(1-y(t)) - y(t)(k_{-1}+k_2)\\
    \end{cases}\\
  \end{align*}

  Since it was assumed that $\epsilon\approx 0$:

  $$\begin{cases}
    \frac{dx(t)}{dt} = 0\\
    \frac{dy(t)}{dt} = k_1s_0x(t)(1-y(t)) - y(t)(k_{-1}+k_2)\\
  \end{cases}$$

  So $x(t)$ is a constant.
  Moreover, given that $x(t) = \frac{s(t)}{s_0}$, and that $s_0$ is a constant, then $s(t)$ is constant.
  This means that it never changes from its initial value, so $x = \frac{s(t)}{s_0} = \frac{s_0}{s_0} = 1$.
  Then a single ODE remains in the system:

  $$\frac{dy}{dt} = k_1s_0(1-y(t)) - y(t)(k_{-1}+k_2)$$

    \subsubsection{Equilibrium points}
    Analyzing the equilibrium points of the system:

    \begin{align*}
      k_1s_0(1-y(t)) - y(t)(k_{-1}+k_2) &= 0\\
      k_1s_0 - k_1s_0y(t) - y(t)(k_{-1} + k_2) &= 0\\
      (k_1s_0 + k_{-1} + k_2)y(t) &= k_1s_0\\
      y(t) &= \frac{k_1s_0}{k_1s_0 + k_{-1} + k_2}\\
    \end{align*}

  \subsection{Slower time-scale}
  In a lower time-scale the system cannot be approximated into a single equation.
  $t$ is replaced by a smaller unit $\tau$ such that:

  $$\tau = \epsilon t$$

  So that when $\epsilon$ is very small, also $\tau$ is very small and the timescale is slowed done.
  Using the chain rule:

  $$\frac{d}{d\tau} = \frac{d}{dt}\frac{dt}{d\tau}$$

  And since $t = \frac{\tau}{\epsilon}$:

  \begin{align*}
    \frac{d}{d\tau} &= \frac{d}{dt}\frac{dt}{d\tau}\\
                    &= \frac{d}{dt}\frac{1}{\epsilon}
  \end{align*}

  Applying this in $x(t)$ and $y(t)$:

  \begin{align*}
    \frac{d}{d\tau}x(\tau) &= \frac{d}{dt}\frac{1}{\epsilon}x(\tau)\\
                        &=\frac{1}{\epsilon}\frac{dx(t)}{dt}\\
  \end{align*}

  \begin{align*}
    \frac{d}{d\tau}y(\tau) &= \frac{d}{dt}\frac{1}{\epsilon}y(\tau)\\
                        &=\frac{1}{\epsilon}\frac{dy(t)}{dt}\\
  \end{align*}

  So the system can be switched to the slower time scale by dividing by $\epsilon$:

  \begin{align*}
    \begin{cases}
      \frac{dx(\tau)}{d\tau} &= \frac{1}{\cancel{\epsilon}}\cancel{\epsilon}[k_{-1}y(\tau) - k_1x(\tau)s_0(1-y(\tau))]\\
      \frac{dy(\tau)}{\tau} &= \frac{1}{\epsilon}[k_1s_0x(\tau)(1-y(\tau)) - y(\tau)(k_{-1}+k_2)]\\
    \end{cases}\\
    \begin{cases}
      \frac{dx(\tau)}{d\tau} &= k_{-1}y(\tau) - k_1x(\tau)s_0(1-y(\tau))\\
      \frac{dy(\tau)}{\tau} &= \frac{1}{\epsilon}[k_1s_0x(\tau)(1-y(\tau)) - y(\tau)(k_{-1}+k_2)]\\
    \end{cases}\\
  \end{align*}

  Switching back to the fast timescale for the second equation:

  $$\begin{cases}
    \frac{dx(\tau)}{d\tau} &= k_{-1}y(\tau) - k_1x(\tau)s_0(1-y(\tau))\\
      \frac{dy(t)}{dt} = \epsilon\frac{dy(\tau)}{\tau} &= [k_1s_0x(\tau)(1-y(\tau)) - y(\tau)(k_{-1}+k_2)]\\
  \end{cases}$$

  But, since $\epsilon \approx 0$:

  $$\begin{cases}
      \frac{dx(\tau)}{d\tau} &= k_{-1}y(\tau) - k_1x(\tau)s_0(1-y(\tau))\\
      0 &= [k_1s_0x(\tau)(1-y(\tau)) - y(\tau)(k_{-1}+k_2)]\\
  \end{cases}$$

  The second equation allow to extract the equilibrium value $\tilde{y}$ for $y(t)$ in the slower timescale:

  \begin{align*}
    [k_1s_0x(\tau)(1-\tilde{y}(\tau)) - \tilde{y}(\tau)(k_{-1}+k_2)] &= 0\\
    k_1s_0x(\tau)-k_1s_0x(\tau)\tilde{y}(\tau) - \tilde{y}(\tau)(k_{-1}+k_2) &= 0\\
    (k_1s_0x(\tau) + k_{-1} + k_2)\tilde{y}(\tau) &= k_1s_0x(\tau)\\
    \tilde{y}(\tau) &= \frac{k_1s_0x(\tau)}{k_1s_0x(\tau) + k_{-1} + k_2}\\
  \end{align*}

  So that it can be subsituted in the first equation:

  \begin{align*}
    \frac{dx(\tau)}{d\tau} &= k_{-1}\tilde{y}(\tau) - k_1x(\tau)s_0(1-\tilde{y}(\tau))\\
                           &= k_{-1}\frac{k_1s_0x(\tau)}{k_1s_0x(\tau)+k_{-1}+k_2} - k_1x(\tau)s_0\left(1-\frac{k_1s_0x(\tau)}{k_1s_0x(\tau)+k_{-1}+k_2}\right)\\
                           &= k_1x(\tau)s_0\frac{k_{-1}}{k_1x(\tau)s_0+k_{-1}+k_2} - k_1x(\tau)s_0\left(1-\frac{k_1s_0x(\tau)}{k_1s_0x(\tau)+k_{-1}+k_2}\right)\\
                           &= k_1x(\tau)s_0\left[\frac{k_{-1}}{k_1x(\tau)s_0+k_{-1}+k_2}-1+\frac{k_1x(\tau)s_0}{k_1x(\tau)s_0+k_{-1}+k_2}\right]\\
                           &= k_1x(\tau)s_0\left[\frac{k_{-1} + k_1x(\tau)s_0}{k_1x(\tau)s_0+k_{-1}+k_2}-1\right]\\
                           &= \frac{(k_1x(\tau)s_0)^2+k_{-1}k_1x(\tau)s_0 - k_1x(\tau)s_0[k_1x(\tau)s_0 + k_{-1} + k_2]}{k_1x(\tau)s_0+k_{-1}+k_2}\\
                           &= \frac{\cancel{(k_1x(\tau)s_0)^2}+\cancel{k_{-1}k_1x(\tau)s_0} - \cancel{(k_1x(\tau)s_0)^2} - \cancel{k_{-1}k_1x(\tau)s_0} - k_2k_{-1}k_1x(\tau)s_0}{k_1x(\tau)s_0+k_{-1}+k_2}\\
                           &= \frac{k_2k_1x(\tau)s_0}{k_1x(\tau)s_0+k_{-1}+k_2}\\
  \end{align*}

  Solving this equation $\tilde{x}(\tau)$, an approximate solution for $x(\tau)$ can be obtained.
  This can be used in the identity of $\tilde{y}(\tau)$ to obtain an approximate equation for $y(\tau)$, approximating a solution for the whole system.\\
  This is called quasi-equilibrium approximation: the timescale is changed to a slower one, and then one equation is reverted back to the quicker time scale that will be equal to $0$.
  In this way that equation is solved so that the solutions for the two equations can be found.

  \subsection{Michaelis Menten's Law}
  Consider now the product:

  $$\frac{dp(t)}{dt} = k_2c(t)$$

  Since $y(t) = \frac{c(t)}{e_0}$:

  $$\frac{dp(t)}{dt} = k_2e_0y(t)$$

  Changing to the slow timescale:

  $$\frac{dp(\tau)}{d\tau} = \frac{k_2e_0y(t)}{\epsilon} = k_2s_0y(\tau)$$

  Assume to have applied the quasi-equilibrium approximation and found a value $\tilde{y}(\tau)$ that can be replaced in there.
  Remembering:

  $$\tilde{y}(\tau) = \frac{k_1x(\tau)s_0}{k_1x(\tau)s_0 + k_{-1} + k_2}$$

  So:

  \begin{align*}
    \frac{dp(\tau)}{d\tau} &= k_2s_0\frac{k_1x(\tau)s_0}{k_1x(\tau)s_0 + k_{-1} + k_2}\\
                         &= \frac{k_1k_2x(\tau)s_0^2}{k_1x(\tau)s_0 + k_{-1} + k_2}\\
  \end{align*}

  And remembering that $x(t) = \frac{s(t)}{s_0}$:

  $$\frac{dp(\tau)}{d\tau} = \frac{k_1k_2s(\tau)s_0}{k_1s(\tau)+k_{-1}+k_2}$$

  Now, multiplying by $\epsilon$ to go to the fast timescale:

  \begin{align*}
    \frac{dp(t)}{dt} = \epsilon\frac{dp(\tau)}{d\tau} &= \epsilon\frac{k_1k_2s(t)s_0}{k_1s(t)+k_{-1}+k_2}\\
                                                      &= \frac{e_0}{\cancel{s_0}}\frac{k_1k_2s(t)\cancel{s_0}}{k_1s(t)+k_{-1}+k_2}
                                                      &= \frac{\cancel{k_1}k_2s(t)e_0}{\cancel{k_1}s(t)+\frac{\cancel{k_1}(k_{-1}+k_2)}{k_1}}\\
                                                      &= \frac{k_2s(t)e_0}{s(t)+\frac{k_{-1}+k_2}{k_1}}\\
  \end{align*}

  Given that $k_2$ and $e_0$ are constants, introduce $m = k_2e_0$, the same for $\frac{k_{-1}+k_2}{k_1}=s_h$, or the half saturation constant so that the Michaelis Menten's Law is obtained:

  $$\frac{dp(t)}{dt} = \frac{ms(t)}{s(t) + s_h}$$

  Where:

  \begin{multicols}{2}
    \begin{itemize}
      \item $m = k_2e_0$
      \item $s_h = \frac{k_{-1}+k_2}{k_1}$
    \end{itemize}
  \end{multicols}

  This law links the speed at which the product of an enzymatic reaction is produced to the concentration of substrate.
  THe half saturation constant $s_h$ is the value of the concentration of $S$such that the rate of production of the product is hal of its maximum.
  The rate of production will increase until saturation with maximum value $m$ as the concentration of substrate grows to infinity.

  \subsection{Enzymatic reaction with reversible production}
  An enzymatic reaction with reversible production follows:

  $$S + E \xrightleftharpoons[k_{-1}]{k_1} ES \xrightleftharpoons[k_{-2}]{k_2} E + P$$

  The system is:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)e(t) + k_{-1}c(t)\\
    \frac{de(t)}{dt} &= -k_1s(t)e(t) + k_{-1}c(t) + k_2c(t) - k_{-2}p(t)e(t)\\
    \frac{dc(t)}{dt} &= k_1s(t)e(t) - k_{-1}c(t) - k_2c(t) + k_{-2}p(t)e(t)\\
    \frac{dp(t)}{dt} &= k_2c(t) - k_{-2}p(t)e(t)\\
  \end{cases}$$

  It can be seen that:

  \begin{align*}
    \frac{d}{dt}[e(t)+c(t)] &= 0\Rightarrow e(t) + c(t) = k = e_0\\
    \frac{d}{dt}[s(t) + c(t) + p(t)] &= 0\Rightarrow s(t) + c(t) + p(t) = k =  s_0\\
  \end{align*}

  Given that at any instant $e(t)$ can be recovered from $c(t)$ and $p(t)$ from $s(t)$ and $c(t)$, the system can be reduced to:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)(e_0-c(t)) + k_{-1}c(t)\\
    \frac{dc(t)}{dt} &= k_1s(t)(e_0-c(t)) - k_{-1}c(t) - k_2c(t) + k_{-2}(s_0-s(t)-c(t))(e_0-c(t))\\
  \end{cases}$$

    \subsubsection{Normalization}

    $$x(t) = \frac{s(t)}{s_0}\qquad\qquad y(t) = \frac{c(t)}{e_0}\qquad\qquad\epsilon = \frac{e_0}{s_0}\ll 1$$

    \begin{align*}
      \begin{cases}
        s_0\frac{dx(t)}{dt} &= -k_1s_0x(t)(e_0-e_0y(t)) + k_{-1}e_0y(t)\\
        e_0\frac{dy(t)}{dt} &= k_1s_0x(t)(e_0-e_0y(t)) - k_{-1}e_0y(t) - k_2e_0y(t) + k_{-2}(s_0-s_0x(t)-e_0y(t))(e_0-e_0y(t))\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} &= -k_1s_0\frac{e_0}{s_0}x(t)(1-y(t)) + k_{-1}\frac{e_0}{s_0}y(t)\\
        \frac{dy(t)}{dt} &= k_1s_0x(t)(1-y(t)) - k_{-1}y(t) - k_2y(t) + k_{-2}s_0(1-x(t)-\frac{e_0}{s_0}y(t))(1-y(t))\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} &= -k_1s_0\epsilon x(t)(1-y(t)) + k_{-1}\epsilon y(t)\\
        \frac{dy(t)}{dt} &= k_1s_0x(t)(1-y(t)) - k_{-1}y(t) - k_2y(t) + k_{-2}s_0(1-x(t)-\epsilon y(t))(1-y(t))\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} &= \epsilon[-k_1s_0 x(t)(1-y(t)) + k_{-1} y(t)]\\
        \frac{dy(t)}{dt} &= k_1s_0x(t)(1-y(t)) - k_{-1}y(t) - k_2y(t) + k_{-2}s_0(1-x(t)-\epsilon y(t))(1-y(t))\\
      \end{cases}\\
      \epsilon \approx 0\\
      \begin{cases}
        \frac{dx(t)}{dt} &= 0[-k_1s_0 x(t)(1-y(t)) + k_{-1} y(t)]\\
        \frac{dy(t)}{dt} &= k_1s_0x(t)(1-y(t)) - k_{-1}y(t) - k_2y(t) + k_{-2}s_0(1-x(t)-0y(t))(1-y(t))\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} &= 0\\
        \frac{dy(t)}{dt} &= k_1s_0x(t)(1-y(t)) - k_{-1}y(t) - k_2y(t) + k_{-2}s_0(1-x(t))(1-y(t))\\
      \end{cases}\\
    \end{align*}

    So $x(t)$ is a constant.
    Assuming $x(t) = x = 1$:

    $$\frac{dy(t)}{dt} = k_1s_0(1-y(t)) - k_{-1}y(t) - k_2y(t)$$

    \subsubsection{Equilibrium points}

    \begin{align*}
      k_1s_0(1-y(t)) - k_{-1}y(t) - k_2y(t) &= 0\\
      k_1s_0 - k_1s_0y(t) - k_{-1}y(t) - k_2y(t) &= 0\\
      (k_1s_0 - k_{-1} - k_2)y(t) &= k_1s_0\\
      y(t) &= \frac{k_1s_0}{k_1s_0 + k_{-1} + k_2}\\
    \end{align*}

    \subsubsection{Quasi-equilibrium}
    Switching to slower timescales:

    $$\tau = \epsilon t$$

    \begin{align*}
      \frac{d}{\tau}x(\tau) &= \frac{d}{dt}\frac{1}{\tau}x(\tau) = \frac{dx(t)}{dt}\frac{1}{\epsilon}\\
      \frac{d}{\tau}y(\tau) &= \frac{d}{dt}\frac{1}{\tau}y(\tau) = \frac{dy(t)}{dt}\frac{1}{\epsilon}\\
    \end{align*}

    \begin{align*}
      \begin{cases}
        \frac{dx(\tau)}{d\tau} = \frac{dx(t)}{dt}\frac{1}{\epsilon} &= \frac{1}{\cancel{\epsilon}}\cancel{\epsilon}[-k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)]\\
        \frac{dy(\tau)}{d\tau} = \frac{dy(t)}{dt}\frac{1}{\epsilon} &= \frac{1}{\epsilon}\left[k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau)-\epsilon y(\tau))(1-y(\tau))\right]\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)\\
        \frac{dy(\tau)}{d\tau} &= \frac{1}{\epsilon}\left[k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau)-\epsilon y(\tau))(1-y(\tau))\right]\\
      \end{cases}\\
    \end{align*}

    Now applying the quasi-equilibrium conditiona nd reverting to the fast timecale for the second:

    \begin{align*}
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)\\
        \frac{dy(t)}{dt} = \epsilon\frac{dy(\tau)}{d\tau} &= \cancel{\epsilon}\frac{1}{\cancel{\epsilon}}\left[k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau)-\cancel{\epsilon y(\tau)})(1-y(\tau))\right]\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)\\
        \frac{dy(t)}{dt} = \epsilon\frac{dy(\tau)}{d\tau} &= \cancel{\epsilon}\frac{1}{\cancel{\epsilon}}\left[k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau))(1-y(\tau))\right]\\
      \end{cases}\\
      \epsilon \approx 0\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)\\
        0 &= k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau))(1-y(\tau))\\
      \end{cases}\\
    \end{align*}

    Now extracting $\tilde{y}(\tau)$:

    \begin{align*}
      &k_1s_0x(\tau)(1-y(\tau)) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau))(1-y(\tau)) = 0\\
      &k_1s_0x(\tau) - k_1s_0x(\tau)y(\tau) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0(1-x(\tau) -y(\tau) + x(\tau)y(\tau)) = 0\\
      &k_1s_0x(\tau) - k_1s_0x(\tau)y(\tau) - k_{-1}y(\tau) - k_2y(\tau) + k_{-2}s_0-k_{-2}s_0x(\tau) -k_{-2}s_0y(\tau) + k_{-2}s_0x(\tau)y(\tau)) = 0\\
      &[-k_1s_0x(\tau)-k_{-1} - k_2 - k_{-2}s_0+k_{-2}s_0x(\tau)]y(\tau) = -k_1s_0x(\tau) - k_{-2}s_0 - k_{-2}s_0x(\tau)\\
      &y(\tau) = -\frac{k_1s_0x(\tau) + k_{-2}s_0 + k_{-2}s_0x(\tau)}{-k_1s_0x(\tau)-k_{-1} - k_2 - k_{-2}s_0+k_{-2}xs_0(\tau)}\\
      &y(\tau) = \frac{k_1s_0x(\tau) + k_{-2}s_0 + k_{-2}s_0x(\tau)}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
    \end{align*}

    At this point it can be plugged into the equation for $\frac{dx(\tau)}{d\tau}$:

    $$\frac{dx(\tau)}{d\tau} = -k_1s_0 x(\tau)(1-y(\tau)) + k_{-1} y(\tau)$$

    \begin{align*}
      1- y(\tau) &= 1 - \frac{k_1s_0x(\tau) + k_{-2}s_0 + k_{-2}s_0x(\tau)}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}x(\tau)}\\
                 &= \frac{\cancel{k_1s_0x(\tau)}+k_{-1} + k_2 + \cancel{k_{-2}s_0}-\cancel{k_{-2}s_0x(\tau)} - \cancel{k_1s_0x(\tau)} - \cancel{k_{-2}s_0} - \cancel{k_{-2}s_0x(\tau)}}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
                 &= \frac{k_{-1} + k_2}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
    \end{align*}

    So that:

    \begin{align*}
      \frac{dx(\tau)}{d\tau} &= \frac{-k_1s_0x(\tau)(k_{-1} + k_{2})}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)} + \frac{k_{-1}k_1x(\tau)s_0 + k_{-1}k_{-2}s_0 - k_{-1}k_{-2}s_0x(\tau)}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
                             &= \frac{\cancel{-k_1k_{-1}s_0x(\tau)}-k_1k_2s_0x(\tau) +\cancel{k_{-1}k_1x(\tau)s_0} + k_{-1}k_{-2}s_0 - k_{-1}k_{-2}s_0x(\tau)}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
                             &= \frac{-k_1k_2s_0x(\tau) + k_{-1}k_{-2}s_0 - k_{-1}k_{-2}s_0x(\tau)}{k_1s_0x(\tau)+k_{-1} + k_2 + k_{-2}s_0-k_{-2}s_0x(\tau)}\\
    \end{align*}

    In order to apply Tikhonov's theorem, the equation has to be solved, finding $\tilde{x}(\tau)$, then it would be plugged into $\tilde{y}(\tau)$ to obtain $\bar{y}(\tau)$.
    At this point for $\epsilon\to 0$ the exact solution converges to the degenerate $(\tilde{x}(\tau), \tilde{y}(\tau))$.

  \subsection{Enzymatic inhibition}
  An inhibitory molecule may decrease the rate at which an enzymatic reaction occurs.
  Considering competitive inhibition, let $I$ be the inhibitory molecule, then the competitive inhibition is schematized as:

  \begin{align*}
    S + E &\xrightleftharpoons[k_{-1}]{k_1} ES \xrightarrow{k_2} E + P\\
    I + E &\xrightleftharpoons[k_{-3}]{k_3} EI\\
  \end{align*}

  Let $s = [S]$, $e = [E]$, $i=[I]$, $c_1 = [SE]$, $c_2 = [IE]$ and $p = [P]$:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)e(t) + k_{-1}c_1(t)\\
    \frac{de(t)}{dt} &= -k_1s(t)e(t) + (k_{-1}+k_2)c_1(t) -k_3i(t)e(t) + k_{-3}c_2(t)\\
    \frac{dc_1(t)}{dt} &= k_1s(t)e(t) - (k_{-1}+k_2)c_1(t)\\
    \frac{dp(t)}{dt} &= k_2c_1(t)\\
    \frac{di(t)}{dt} &= -k_3i(t)e(t) + k_{-3}c_2(t)\\
    \frac{dc_2(t)}{dt} &= k_3i(t)e(t) - k_{-3}c_2(t)\\
  \end{cases}$$

  No equation depends on $p$, so it can be eliminated.
  Moreover:

  $$\frac{d}{dt}[e(t)+c_1(t) + c_2(t)] = k = e_0\qquad\qquad e(t) = (e_0-c_1(t) - c_2(t))$$

  So $\frac{de(t)}{dt}$ can be elimintaed from the system.
  Finally $[I]$ is assumed so large that its variation on time are negligible: $\frac{di(t)}{dt} = 0$.
  Now the constant value of $i$ can be recovered:

  \begin{align*}
    \frac{di(t)}{dt} = -k_3i(t)e(t) + k_{-3}c_2(t) &= 0\\
    k_3i(t)(e_0 -c_1(t) - c_2(t)) &=  k_{-3}c_2(t)\\
    i = \frac{k_{-3}c_2(t)}{k_3(e_0 - c_1(t) - c_2(t))}
  \end{align*}

  With these assumptions the system becomes:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)(e_0-c_1(t) - c_2(t)) + k_{-1}c_1(t)\\
    \frac{dc_1(t)}{dt} &= k_1s(t)(e_0-c_1(t) - c_2(t)) - (k_{-1}+k_2)c_1(t)\\
    \frac{dc_2(t)}{dt} &= k_3i(e_0-c_1(t)-c_2(t))-k_{-3}c_2(t)
  \end{cases}$$

    \subsubsection{Normalization}
    Introduce:

    $$x(t) = \frac{s(t)}{s_0}\qquad y_1(t) = \frac{c_1(t)}{e_0}\qquad y_2(t) = \frac{c_2(t)}{e_0}\qquad \epsilon = \frac{e_0}{s_0}\ll 1$$

    \begin{align*}
      \begin{cases}
        s_0\frac{dx(t)}{dt} = -k_1s_0x(t)(e_0-e_0y_1(t) - e_0y_2(t)) + k_{-1}e_0y_1(t)\\
        e_0\frac{dy_1(t)}{dt} = k_1s_0x(t)(e_0-e_0y_1(t) - e_0y_2(t)) - (k_{-1}+k_2)e_0y_1(t)\\
        e_0\frac{y_2(t)}{dt} = k_3i(e_0-e_0y_1(t)-e_0y_2(t))-k_{-3}e_0y_2(t)
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} = -k_1\frac{e_0}{s_0}s_0x(t)(1-y_1(t) -y_2(t)) + k_{-1}\frac{e_0}{s_0}y_1(t)\\
        \frac{dy_1(t)}{dt} = k_1s_0x(t)(1-y_1(t) -y_2(t)) - (k_{-1}+k_2)y_1(t)\\
        \frac{y_2(t)}{dt} = k_3i(1-y_1(t)-y_2(t))-k_{-3}y_2(t)
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} = -k_1\epsilon s_0x(t)(1-y_1(t) -y_2(t)) + k_{-1}\epsilon y_1(t)\\
        \frac{dy_1(t)}{dt} = k_1s_0x(t)(1-y_1(t) -y_2(t)) - (k_{-1}+k_2)y_1(t)\\
        \frac{y_2(t)}{dt} = k_3i(1-y_1(t)-y_2(t))-k_{-3}y_2(t)/
      \end{cases}\\
      \begin{cases}
        \frac{dx(t)}{dt} = \epsilon\left[-k_1s_0x(t)(1-y_1(t) -y_2(t)) + k_{-1}y_1(t)\right]\\
        \frac{dy_1(t)}{dt} = k_1s_0x(t)(1-y_1(t) -y_2(t)) - (k_{-1}+k_2)y_1(t)\\
        \frac{y_2(t)}{dt} = k_3i(1-y_1(t)-y_2(t))-k_{-3}y_2(t)\\
      \end{cases}\\
    \end{align*}

    \subsubsection{Quasi-equilibrium}
    Assume a slower timescale $\tau = \epsilon t$:

    $$\frac{d}{d\tau}x(\tau) = \frac{dx(t)}{dt}\frac{1}{\epsilon}\quad \frac{d}{d\tau}y_1(\tau) = \frac{dy_1(t)}{dt}\frac{1}{\epsilon}\quad \frac{d}{d\tau}y_2(\tau) = \frac{dy_2(t)}{dt}\frac{1}{\epsilon}$$

    $$\begin{cases}
      \frac{dx(\tau)}{d\tau} &= -k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) + k_{-1}y_1(\tau)\\
      \frac{dy_1(\tau)}{d\tau} &= \frac{1}{\epsilon}\left[k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) - (k_{-1}+k_2)y_1(\tau)\right]\\
      \frac{dy_2(\tau)}{d\tau} &= \frac{1}{\epsilon}\left[k_3i(1-y_1(\tau)-y_2(\tau))-k_{-3}y_2(\tau)\right]\\
    \end{cases}$$

    Reverting back to the fast timescale the last two equations:

    \begin{align*}
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) + k_{-1}y_1(\tau)\\
        \epsilon\frac{dy_1(\tau)}{d\tau} &= k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) - (k_{-1}+k_2)y_1(\tau)\\
        \epsilon\frac{dy_2(\tau)}{d\tau} &= k_3i(1-y_1(\tau)-y_2(\tau))-k_{-3}y_2(\tau)\\
      \end{cases}\\
      \epsilon\approx 0\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} &= -k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) + k_{-1}y_1(\tau)\\
        0 &= k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) - (k_{-1}+k_2)y_1(\tau)\\
        0 &= k_3i(1-y_1(\tau)-y_2(\tau))-k_{-3}y_2(\tau)\\
      \end{cases}\\
    \end{align*}

    The last two equations can now be solved:

    \begin{align*}
      k_1s_0x(\tau)(1-y_1(\tau) -y_2(\tau)) - (k_{-1}+k_2)y_1(\tau)&=0\\
      k_1s_0x(\tau)-k_1s_0x(\tau)y_1(\tau) -k_1s_0x(\tau)y_2(\tau)) - k_{-1}y_1(\tau)-k_2y_1(\tau)&=0\\
      [k_1s_0x(\tau) + k_{-1}+k_2]y_1(\tau) &= k_1s_0x(\tau) -k_1s_0x(\tau)y_2(\tau)\\
      y_1(\tau) &=\frac{k_1s_0x(\tau)-k_1s_0x(\tau)y_2(\tau)}{k_1s_0x(\tau) + k_{-1}+k_2}\\
    \end{align*}

    This still depends on $y_2(\tau)$, so we need to solve the last equation:

    \begin{align*}
      k_3i(1-y_1(\tau)-y_2(\tau))-k_{-3}y_2(\tau) &= 0\\
      k_3i\left(1-\frac{k_1s_0x(\tau)-k_1s_0x(\tau)y_2(\tau)}{k_1s_0x(\tau) + k_{-1}+k_2} - y_2(\tau)\right)-k_{-3}y_2(\tau) &= 0\\
      k_3i - \frac{k_3i(k_1s_0x(\tau) - k_1s_0x(\tau)y_2(\tau))}{k_1s_0x(\tau) + k_{-1}+k_2} - k_3iy_2(\tau) -k_{-3}y_2(\tau) &= 0\\
      -\frac{k_3ik_1s_0x(\tau)y_2(\tau)}{k_1s_0x(\tau) + k_{-1}+k_2} + k_3iy_2(\tau) + k_{-3}y_2(\tau) &= k_3i - \frac{k_3ik_1s_0x(\tau)}{k_1s_0x(\tau) + k_{-1} + k_2}\\
      \frac{-k_3ik_1s_0x(\tau) + k_3i(k_1s_0x(\tau) + k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}{k_1s_0x(\tau) + k_{-1} + k_2}y_2(\tau) &= \frac{k_3i(k_1s_0x(\tau) + k_{-1} + k_2)}{k_1s_0x(\tau) + k_{-1} + k_2} +\\&- \frac{k_3ik_1s_0x(\tau)}{k_1s_0x(\tau) + k_{-1} + k_2}\\
      (\cancel{-k_3ik_1s_0x(\tau)} + \cancel{k_3ik_1s_0x(\tau)} + k_3ik_{-1} - k_3ik_2 + k_{-3}k_1s_0x(\tau) + k_{-3}k_{-1} + k_{-3}k_2)y_2(t) &= \cancel{k_3ik_1s_0x(\tau)} + k_3ik_{-1} + k_3ik_2 +\\&- \cancel{k_3ik_1s_0x(\tau)}\\
      y_2(\tau) = \frac{k_3ik_{-1}+k_3ik_2}{k_3ik_{-1} - k_3ik_2 + k_{-3}k_1s_0x(\tau) + k_{-3}k_{-1} + k_{-3}k_2}\\
      \tilde{y}_2(\tau) = \frac{k_3i(k_{-1} + k_2)}{k_3i(k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}\\
    \end{align*}

    Now, replugging into $y_1(\tau)$:

    \begin{align*}
      y_1(\tau) &=\frac{k_1s_0x(\tau)-k_1s_0x(\tau)y_2(\tau)}{k_1s_0x(\tau) + k_{-1}+k_2}\\
       &=\frac{k_1s_0x(\tau)\left(1-\frac{k_3i(k_{-1} + k_2)}{k_3i(k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}\right)}{k_1s_0x(\tau) + k_{-1}+k_2}\\
       &=\frac{k_1s_0x(\tau)\frac{\cancel{k_3i(k_{-1} + k_2)} + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2) -  \cancel{k_3i(k_{-1} + k_2)}}{k_3i(k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}}{k_1s_0x(\tau) + k_{-1}+k_2}\\
       &=\frac{\frac{k_1s_0x(\tau)k_{-3}\cancel{(k_1s_0x(\tau) + k_{-1} + k_2)}}{k_3i(k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}}{\cancel{k_1s_0x(\tau) + k_{-1}+k_2}}\\
      \tilde{y}_1(\tau) &=\frac{k_1s_0x(\tau)k_{-3}}{k_3i(k_{-1} + k_2) + k_{-3}(k_1s_0x(\tau) + k_{-1} + k_2)}\\
    \end{align*}

    In order to apply TIkhonov's theorem, the two solutions will be plugged into $\frac{dx(\tau)}{\tau}$, solving the differential equation and plugging the values of $x(\tau)$ into the two soution.

    \subsubsection{Rate of production of the product}
    Now, since the objective is to find an explicit way to track the rate of production of the product and considering:

    $$\frac{dp(t)}{dt} = k_2c_1(t) \qquad\land\qquad \frac{dp(t)}{dt} = k_2y_1(t)e_0$$

    And transitioning to the slow timescale"

    \begin{align*}
      \frac{dp(\tau)}{d\tau} &= \frac{dp(t)}{dt}\frac{1}{\epsilon}\\
                             &= \frac{k_2y_1(\tau)e_0}{\epsilon}\\
                             &= k_2y_1(\tau)s_0
    \end{align*}

    Pligging the value for $\tilde{y})1(\tau)$:

    \begin{align*}
      \frac{dp(\tau)}{d\tau} &= k_2s_0\frac{k_1(s_0x(\tau))k_{-3}}{k_{-3}(k_{-1} + k_2 + k_1s_0x(\tau)) + k_3i(k_{-1} + k_2)}\\
      &= \frac{k_2s_0k_1s(\tau)k_{-3}}{k_{-3}(k_{-1} + k_2 + k_1s_0x(\tau)) + k_3i(k_{-1} + k_2)}\\
    \end{align*}

    And going back to the fast timescale:

    \begin{align*}
      \epsilon\frac{dp(\tau)}{d\tau} = \frac{dp(t)}{dt} &= \frac{\epsilon k_2s_0k_1s(\tau)k_{-3}}{k_{-3}(k_{-1} + k_2 + k_1s_0x(\tau)) + k_3i(k_{-1} + k_2)}\\
                                                        &=\frac{k_2e_0k_1s(t)k_{-3}}{k_{-3}(k_{-1} + k_2 + k_1s_0x(t)) + k_3i(k_{-1} + k_2)}\\
                                                        &=\frac{\frac{k_2e_0k_1s(t)k_{-3}}{k_1k_{-3}}}{\frac{k_{-3}(k_{-1} + k_2 + k_1s_0x(t)) + k_3i(k_{-1} + k_2)}{k_1k_{-3}}}\\
                                                        &=\frac{\frac{k_2e_0\cancel{k_1}s(t)\cancel{k_{-3}}}{\cancel{k_1}\cancel{k_{-3}}}}{\frac{\cancel{k_{-3}}}{k_1\cancel{k_{-3}}}(k_{-1} + k_2 + k_1s(t)) + \frac{k_3i}{k_1k_{-3}}(k_{-1} + k_2)}\\
                                                        &=\frac{k_2e_0s(t)}{\frac{k_{-1} + k_2}{k_1} + \frac{\cancel{k_1}s(t)}{\cancel{k_1}} + \frac{k_3i}{k_1k_{-3}}(k_{-1} + k_2)}\\
                                                        &=\frac{k_2e_0s(t)}{\frac{k_{-1} + k_2}{k_1} + s(t) + \frac{k_3i}{k_1k_{-3}}(k_{-1} + k_2)}\\
    \end{align*}

    Now setting $m = k_2e_0$, $s_h = \frac{k_{-1} + k_2}{k_1}$ and $s_i = \frac{k_3i}{k_1k_{_3}}(k_{-1}+k_2)$:

    $$\frac{dp(t)}{dt} = \frac{ms(t)}{s_h + s(t) + s_i}$$

    Which is the speed of production of $p$.
    So adding an inhibitor will increase the half saturation constant from $s_h$ to $s_h+s_i$, decreasing the reaction rate when the substrate is not abundant.
    When it grows to infinity, the enzyme is still capable of reaching its maximum speed $m$.

  \subsection{Cooperativity}
  In cooperativity an enzyme can bind up to two substrate molecules.
  The reaction scheme is:

  \begin{align*}
    S + E &\xrightleftharpoons[k_{-1}]{k_1} C_1 \xrightarrow{k_2} E + P\\
    C_1 + S &\xrightleftharpoons[k_{-3}]{k_3} C_2\xrightarrow{k_4} P + C_1\\
  \end{align*}

  This happens when the binding of the first molecule changes the enzyme configuration and changing the rate at which further binding occurs.
  An extreme degree happens when $k_1$ is very low and $k_3$ is very high.
  On the other hand independence means that $k_1 = 2k_3$ and $k_{-3} = 2k_{-1}$.
  Moreover independence implies that $k_4 = k_2$.
  The ODE system is:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)e(t) + k_{-1}c_1(t) -k_3c_1(t)s(t) + k_{-3}c_2(t)\\
    \frac{de(t)}{dt} &= -k_1s(t)e(t) + k_{-1}c_1(t) + k_2c_1(t)\\
    \frac{dc_1(t)}{dt} &= k_1s(t)e(t) - k_{-1}c_1(t) - k_2c_1(t) - k_3c_1(t)s(t) + k_{-3}c_2(t) + k_4c_2(t)\\
    \frac{dc_2(t)}{dt} &= k_3c_1(t)s(t) - k_{-3}c_2(t) - k_4c_2(t)\\
    \frac{dp(t)}{dt} &= k_2c_1(t) + k_4c_2(t)\\
  \end{cases}$$

  $p$ appears in only one equation, so it can be recovered from other quantities.
  Moreover:

  $$\frac{d}{dt}[e(t) + c_1(t) + c_2(t)] = 0\Rightarrow e(t)+c_1(t) + c_2(t) = k = e_0$$

  So that the dynamics of $e$ can be expluded.
  So the system becomes:

  $$\begin{cases}
    \frac{ds(t)}{dt} &= -k_1s(t)(e_0-c_1(t)-c_2(t)) + k_{-1}c_1(t) -k_3c_1(t)s(t) + k_{-3}c_2(t)\\
    \frac{dc_1(t)}{dt} &= k_1s(t)(e_0-c_1(t)-c_2(t)) - (k_{-1}+k_2)c_1(t) - k_3c_1(t)s(t) + k_{-3}c_2(t) + k_4c_2(t)\\
    \frac{dc_2(t)}{dt} &= k_3c_1(t)s(t)-k_{-3}c_2(t)-k_4c_2(t)\\
  \end{cases}$$

    \subsubsection{Normalization}
    Let:

    $$x(t) = \frac{s(t)}{s_0}\qquad y_1(t) = \frac{c_1(t)}{e_0}\qquad y_2(t) = \frac{c_2(t)}{e_0}\qquad\epsilon = \frac{e_0}{s_0}\ll 1$$

    Then the system becomes:

    \begin{align*}
      &\begin{cases}
        s_0\frac{dx(t)}{dt} &= -k_1s_0x(t)(e_0-e_0y_1(t)-e_0y_2(t)) + k_{-1}e_0y_1(t) -k_3e_0y_1(t)s(t) + k_{-3}e_0y_2(t)\\
        e_0\frac{dy_1(t)}{dt} &= k_1s_0x(t)(e_0-e_0y_1(t)-e_0y_2(t)) - (k_{-1}+k_2)e_0y_1(t) - k_3e_0y_1(t)s_0x(t) + k_{-3}e_0y_2(t) + k_4e_0y_2(t)\\
        e_0\frac{dy_2(t)}{dt} &= k_3e_0y_1(t)s_0x(t)-k_{-3}e_0y_2(t)-k_4e_0y_2(t)\\
      \end{cases}\\
      &\begin{cases}
        \frac{dx(t)}{dt} &= -k_1s_0x(t)\frac{e_0}{s_0}(1-y_1(t)-y_2(t)) + k_{-1}\frac{e_0}{s_0}y_1(t) -k_3\frac{e_0}{s_0}y_1(t)s(t) + k_{-3}\frac{e_0}{s_0}y_2(t)\\
        \frac{dy_1(t)}{dt} &= k_1s_0x(t)(1-y_1(t)-y_2(t)) - (k_{-1}+k_2)y_1(t) - k_3y_1(t)s_0x(t) + k_{-3}y_2(t) + k_4y_2(t)\\
        \frac{dy_2(t)}{dt} &= k_3y_1(t)s_0x(t)-k_{-3}y_2(t)-k_4y_2(t)\\
      \end{cases}\\
      &\begin{cases}
        \frac{dx(t)}{dt} &= -k_1s_0x(t)\epsilon(1-y_1(t)-y_2(t)) + k_{-1}\epsilon y_1(t) -k_3\epsilon y_1(t)s(t) + k_{-3}\epsilon y_2(t)\\
        \frac{dy_1(t)}{dt} &= k_1s_0x(t)(1-y_1(t)-y_2(t)) - (k_{-1}+k_2)y_1(t) - k_3y_1(t)s_0x(t) + k_{-3}y_2(t) + k_4y_2(t)\\
        \frac{dy_2(t)}{dt} &= k_3y_1(t)s_0x(t)-k_{-3}y_2(t)-k_4y_2(t)\\
      \end{cases}\\
      &\begin{cases}
        \frac{dx(t)}{dt} &= \epsilon\left[-k_1s_0x(t)(1-y_1(t)-y_2(t)) + k_{-1}y_1(t) -k_3y_1(t)s(t) + k_{-3}y_2(t)\right]\\
        \frac{dy_1(t)}{dt} &= k_1s_0x(t)(1-y_1(t)-y_2(t)) - (k_{-1}+k_2)y_1(t) - k_3y_1(t)s_0x(t) + k_{-3}y_2(t) + k_4y_2(t)\\
        \frac{dy_2(t)}{dt} &= k_3y_1(t)s_0x(t)-k_{-3}y_2(t)-k_4y_2(t)\\
      \end{cases}\\
    \end{align*}

    \subsubsection{Changing timescale}
    Let:

    $$\tau = \frac{t}{\epsilon}$$

    Then:

    \begin{align*}
      \begin{cases}
        \frac{dx(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dx(t)}{dt} &= -k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) + k_{-1}y_1(\tau) -k_3y_1(\tau)s(\tau) + k_{-3}y_2(\tau)\\
        \frac{dy_1(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dy_1(t)}{dt} &= \frac{1}{\epsilon}\left[k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) - (k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau)\right]\\
        \frac{dy_2(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dy_2(t)}{dt} &= \frac{1}{\epsilon}\left[k_3y_1(\tau)s_0x(\tau)-k_{-3}y_2(\tau)-k_4y_2(\tau)\right]\\
      \end{cases}\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dx(t)}{dt} &= -k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) + k_{-1}y_1(\tau) -k_3y_1(\tau)s(\tau) + k_{-3}y_2(\tau)\\
        \frac{dy_1(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dy_1(t)}{dt} &= \frac{1}{\epsilon}\left[k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) - (k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau)\right]\\
        \frac{dy_2(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dy_2(t)}{dt} &= \frac{1}{\epsilon}\left[k_3y_1(\tau)s_0x(\tau)-k_{-3}y_2(\tau)-k_4y_2(\tau)\right]\\
      \end{cases}\\
      \text{Switching to fast timescale for the last two equation:}\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dx(t)}{dt} &= -k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) + k_{-1}y_1(\tau) -k_3y_1(\tau)s(\tau) + k_{-3}y_2(\tau)\\
        \epsilon\frac{dy_1(\tau)}{d\tau} = \frac{dy_1(t)}{dt} &= k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) - (k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau)\\
        \epsilon\frac{dy_2(\tau)}{d\tau} = \frac{dy_2(t)}{dt} &= k_3y_1(\tau)s_0x(\tau)-k_{-3}y_2(\tau)-k_4y_2(\tau)\\
      \end{cases}\\
      \epsilon\approx 0\\
      \begin{cases}
        \frac{dx(\tau)}{d\tau} = \frac{1}{\epsilon}\frac{dx(t)}{dt} &= -k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) + k_{-1}y_1(\tau) -k_3y_1(\tau)s(\tau) + k_{-3}y_2(\tau)\\
        0 &= k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) - (k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau)\\
        0 &= k_3y_1(\tau)s_0x(\tau)-k_{-3}y_2(\tau)-k_4y_2(\tau)\\
      \end{cases}\\
    \end{align*}

    To find quasi-equilibria solve first for $y_2(\tau)$:

    \begin{align*}
      &k_3y_1(\tau)s_0x(\tau)-k_{-3}y_2(\tau)-k_4y_2(\tau) = 0\\
      [k_{-3}+k_4]y_2(\tau) &= k_3y_1(\tau)s_0x(\tau)\\
      y_2(\tau) &= \frac{k_3y_1(\tau)s_0x(\tau)}{k_{-3}+k_4}\\
    \end{align*}

    Then for $y_1(\tau)$:

    \begin{align*}
      &k_1s_0x(\tau)(1-y_1(\tau)-y_2(\tau)) - (k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau) = 0\\
      &k_1s_0x(\tau) -k_1s_0x(\tau)y_1(\tau)-k_1s_0x(\tau)y_2(\tau) -(k_{-1}+k_2)y_1(\tau) - k_3y_1(\tau)s_0x(\tau) + k_{-3}y_2(\tau) + k_4y_2(\tau) = 0\\
      &[-k_1s_0x(\tau)-k_{-1}-k_2 -k_3s_0x(\tau)]y_1(\tau) = k_1s_0x(\tau)y_2(\tau) - k_{-3}y_2(\tau) - k_4y_2(\tau)-k_1s_0x(\tau)\\
      &[(k_1 + k_3)s_0x(\tau)+k_{-1}+k_2]y_1(\tau) =  (k_{-3} + k_4 - k_1s_0x(\tau))y_2(\tau) + k_1s_0x(\tau)\\
      &y_1(t) = \frac{(k_{-3} + k_4 - k_1s_0x(\tau))y_2(\tau) + k_1s_0x(\tau)}{(k_1 + k_3)s_0x(\tau)+k_{-1}+k_2}\\
    \end{align*}

    Now, substituting $y_2(\tau)$:

    \begin{align*}
      y_1(t) &= \frac{(k_{-3} + k_4 - k_1s_0x(\tau))\frac{k_3y_1(\tau)s_0x(\tau)}{k_{-3}+k_4} + k_1s_0x(\tau)}{(k_1 + k_3)s_0x(\tau)+k_{-1}+k_2}\\
      y_1(t) &= \frac{\cancel{(k_{-3} + k_4)}\frac{k_3y_1(\tau)s_0x(\tau)}{\cancel{k_{-3}+k_4}} - k_1s_0x(\tau)\frac{k_3y_1(\tau)s_0x(\tau)}{k_{-3} + k_4} + k_1s_0x(\tau)}{(k_1+k_3)s_0x(\tau) + k_{-1} + k_2}\\
      y_1(t) &=\frac{k_3y_1(\tau)s_0x(\tau) - \frac{k_1k_3y_1(\tau)s_0^2x^2(\tau)}{k_{-3} + k_4} + k_1s_0x(\tau)}{(k_1+k_3)s_0x(\tau) + k_{-1} + k_2}\\
      [k_1s_0x(\tau) &+ k_3s_0x(\tau) + k_{-1} + k_2]y_1(t) = k_3s_0x(\tau)y_1(\tau) - \frac{k_1k_3s_0^2x^2(\tau)y_1(\tau)}{k_{-3} + k_4} + k_1s_0x(\tau)\\
      [k_1s_0x(\tau) &+ \cancel{k_3s_0x(\tau)} + k_{-1} + k_2 - \cancel{k_3s_0x(\tau)} + \frac{k_1k_3s_0^2x^2(\tau)}{k_{-3} + k_4}]y_1(t) = + k_1s_0x(\tau)\\
      \tilde{y}_1(\tau) &= \frac{k_1s_0x(\tau)}{k_1s_0x(\tau) + k_2 + k_{-1} + \frac{k_1k_3s_0^2x^2(\tau)}{k_{-3} + k_4}}\\
    \end{align*}

    So now, in $y_2(\tau)$:

    \begin{align*}
      \tilde{y}_2(\tau) &= \frac{k_3\frac{k_1s_0x(\tau)}{k_1s_0x(\tau) + k_2 + k_{-1} + \frac{k_1k_3s_0^2x^2(\tau)}{k_{-3} + k_4}}s_0x(\tau)}{k_{-3}+k_4}\\
                        &= \frac{k_3k_1s^2_0x^2(\tau)}{(k_{-3}+k_4)\left(k_1s_0x(\tau) + k_2 + k_{-1} + \frac{k_1k_3s_0^2x^2(\tau)}{k_{-3} + k_4}\right)}\\
                        &= \frac{k_3k_1s^2_0x^2(\tau)}{(k_{-3}+k_4)(k_1s_0x(\tau) + k_2 + k_{-1}) + k_1k_3s_0^2x^2(\tau)}\\
    \end{align*}

    To solve Tikhonov those values would be fed into $\frac{dx(\tau)}{d\tau}$ to btain an equation from which to deriver $\bar{x}(t)$ and use it to derive $\bar{y}_1(t)$ and $\bar{y}_2(t)$.

    \subsubsection{Rate of production of the product}
    Since the interest is in the rate of production of the product, consider:

    $$\frac{dp(t)}{dt} = k_2c_1(t) + k_4c_2(t)$$

    Applying the normalizations:

    $$\frac{dp(t)}{dt} = k_2e_0y_1(t) + k_4e_0y_2(t)$$

    And transitioning to the slow time-scale:

    \begin{align*}
      \frac{dp(\tau)}{d\tau} &= \frac{dp(t)}{dt}\frac{1}{\epsilon}\\
                             &= k_2y_1(\tau)\frac{e_0}{\epsilon} + k_4\frac{e_0}{\epsilon}y_2(\tau)\\
                             &= k_2y_1(\tau)s_0 + k_4y_2(\tau)s_0
    \end{align*}

    Plugging the values for $\tilde{y}_1(\tau)$ and $\tilde{y}_2(\tau)$:

    \begin{align*}
      \frac{dp(\tau)}{d\tau} &= k_2s_0\frac{k_1s_0x(\tau)}{k_1s_0x(\tau) + k_{-1} + k_2+ \frac{k_1k_3s_0^2x^2(\tau)}{k_{-3} + k_4}} + k_4s_0\frac{k_1k_3s_0^2x^2(\tau)}{(k_{-3}+k_4)(k_1s_0x(\tau) + k_2 + k_{-1}) + k_1k_3s_0^2x^2(\tau)}\\
                             &= k_2s_0\frac{k_1s(\tau)}{k_1s(\tau) + k_{-1} + k_2+ \frac{k_1k_3s^2(\tau)}{k_{-3} + k_4}} + k_4s_0\frac{k_1k_3s^2(\tau)}{(k_{-3}+k_4)(k_1s(\tau) + k_2 + k_{-1}) + k_1k_3s^2(\tau)}\\
                             &= \frac{k_1k_2s_0s(\tau)(k_{-3}+k_4)}{(k_{-3}+k_4)(k_1s(\tau) + k_{-1} + k_2)+ k_1k_3s^2(\tau)} + \frac{k_1k_3k_4s_0s^2(\tau)}{(k_{-3}+k_4)(k_1s(\tau) + k_2 + k_{-1}) + k_1k_3s^2(\tau)}\\
                             &= \frac{k_1k_2s_0s(\tau)(k_{-3}+k_4) + k_1k_3k_4s_0s^2(\tau)}{(k_{-3}+k_4)(k_1s(\tau) + k_{-1} + k_2)+ k_1k_3s^2(\tau)}\\
    \end{align*}

    Going back to the fast time-scale:

    \begin{align*}
      \epsilon\frac{dp(\tau)}{d\tau} = \frac{dp(t)}{dt} &= \epsilon\frac{k_1k_2s_0s(t)(k_{-3}+k_4) + k_1k_3k_4s_0s^2(t)}{(k_{-3}+k_4)(k_1s(t) + k_{-1} + k_2)+ k_1k_3s^2(t)}\\
                                                        &= \frac{e_0}{s_0}\frac{k_1k_2s_0s(t)(k_{-3}+k_4) + k_1k_3k_4s_0s^2(t)}{(k_{-3}+k_4)(k_1s(t) + k_{-1} + k_2)+ k_1k_3s^2(t)}\\
                                                        &= \frac{k_1k_2e_0s(t)(k_{-3}+k_4) + k_1k_3k_4e_0s^2(t)}{(k_{-3}+k_4)(k_1s(t) + k_{-1} + k_2)+ k_1k_3s^2(t)}
    \end{align*}

    So depending on the value of the constants this last expression can correpond to different shapes of the function.
    If the binding sites are independent, $k_1 = 2k_3\land k_{-3} = 2k_{_1}\land k_4 = 2k_2$:

    \begin{align*}
      \frac{dp(t)}{dt} &= \frac{k_1k_2e_0s(t)(k_{-3}+k_4) + k_1k_3k_4e_0s^2(t)}{(k_{-3}+k_4)(k_1s(t) + k_{-1} + k_2)+ k_1k_3s^2(t)}\\
                       &= \frac{4k_3k_2e_0s(t)(k_{-1}+k_2) + 4k^2k_3k_2e_0s^2(t)}{(2k_{-1}+2k_2)(2k_3s(t) + k_{-1} + k_2)+ 2k_3k_3s^2(t)}\\
                       &= \frac{2k_3k_2e_0s(t)(2k_{-1}+2k_2) + 2k_3k_32k_2e_0s^2(t)}{2(k_{-1}+k_2)(2k_3s(t) + k_{-1} + k_2)+ 2k_3k_3s^2(t)}\\
                       &= \frac{4k_3k_2e_0s(t)(k_{-1} + k_2 + k_3s(t))}{2[2k_{-1}k_3s(t) + k_{-1}^2 + k_{-1}k_2 + 2k_{2}k_3s(t) + k_{-1}k_2 + 2k^2_2 + k^2_3s^2(t)]}\\
                       &= \frac{\cancelto{4}{2}k_3k_2e_0s(t)(k_{-1} + k_2 + k_3s(t))}{\cancel{2}[2k_{-1}k_3s(t) + k_{-1}^2 + 2k_{-1}k_2 + 2k_{2}k_3s(t) + 2k^2_2 + k^2_3s^2(t)]}\\
                       &= \frac{2k_3k_2e_0s(t)\cancel{(k_{-1} + k_2 + k_3s(t))}}{2(k_{-1} + k_2 + k_3s(t))^{\cancel{2}}}\\
                       &= \frac{2k_3k_2e_0s(t)}{2(k_{-1} + k_2 + k_3s(t))}\\
                       &= \frac{2k_2e_0s(t)}{\frac{k_{-1}+k_2}{k_3} + s(t)}\\
            k_1 = 2k_3 &\\
                       &= \frac{2k_2e_0s(t)}{\frac{2(k_{-1}+k_2)}{k_1} + s(t)}\\
    \end{align*}

    If the sites are totally dependent $k_1\ll 1$ and $k_3\gg 1$.
    The terms with only $k_1$ can be sent to $o$:

    \begin{align*}
      \frac{dp(t)}{dt} &= \frac{\cancel{k_1k_2e_0s(t)(k_{-3}+k_4)} + k_1k_3k_4e_0s^2(t)}{(k_{-3}+k_4)(\cancel{k_1s(t)} + k_{-1} + k_2)+ k_1k_3s^2(t)}\\
                       &= \frac{k_1k_3k_4e_0s^2(t)}{(k_{-3}+k_4)(k_{-1}+k_2) + k_11k_2s^2(t)}\\
                       &= \frac{k_4e_0s^{2}(t)}{\frac{(k_{-3}+k_4)(k_{_1}+k_2)}{k_1k_3} + \frac{\cancel{k_1}\cancel{k_3}}{\cancel{k_1}\cancel{k_3}}s^2(t)}\\
                       &= \frac{k_4e_0s^{2}(t)}{\frac{(k_{-3}+k_4)(k_{_1}+k_2)}{k_1k_3} + s^2(t)}\\
    \end{align*}

    Introducing now:

    $$K = \frac{(k_{-3} + k_4)(k_{-1} + k_2)}{k_1k_3}$$

    Then the equation becomes:

    $$\frac{dp(t)}{dt} = \frac{k_4e_0s^2(t)}{K + s^2(t)}$$

    Or the Hill equation, which is an example of sigmoidal rate equations: the binding of an additional substrate becomes more efficient if there is already a substrate interacting with the enzyme.
    This converges to $k_4e_0$.

\section{Molecular networks}
Molecolar networks consist of a large number of molecular species with complex patterns of interactions.
Now reaction loops will be considered, networks with two moelcular species, each acting on the rates of synthesis and decay of the other.
There are three possible cases:

\begin{multicols}{2}
  \begin{itemize}
    \item Each molecular species has a positive effect on the other (mutual activation), $++$ positive loop.
    \item Each has a negative effect on the other (mutual inhibition), $--$ negative loop.
    \item One has a positive effect, while the other has a negative (activation-inhibitioin), $+-$ negative loop.
  \end{itemize}
\end{multicols}

  \subsection{Signal-response mechanism}
  How the concentration of a substance respons to a stimulus that increase its synthesis rate.
  $S$, the concentration of some substance favouring the synthesis of $X$ is the signal, while the equilibrium concentration of $X$ is the response.

    \subsubsection{Linear response}
    The concentration of $S$ promotes linearly the production of $X$.
    $X$ has a basal production rate $k_0$, the ODE governing the system will be:

    $$\frac{dX(t)}{dt} = k_0 + k_1S(t) - k_2X(t)$$

    The response is the concentration of $X$ at equiibrium:

    \begin{align*}
      k_0 + k_1S(t) - k_2X_{eq} &= 0\\
      X_{eq} &= \frac{k_0 + k_1S(t)}{k_2}\\
    \end{align*}

    \subsubsection{Hyperbolic response}
    The molecule $X$ can be present in an active state $X_a$ and inactive $X_i$.
    $S$ promotes the transition towards the active state.
    $S$ and $X_i$ partecipate to the productiono f $X_a$:

    $$\frac{dX_a(t)}{dt} = k_1S(t)X_i(t) - k_2X_a(t)$$

    Introducing $X_T = X_a + X_i$:

    $$\frac{dX_a(t)}{dt} = k_1S(t)(X_T - X_a(t)) - k_2X_a(t)$$

    Computing now the equilibrium:

    \begin{align*}
      k_1S(t)(X_T - X_a(t)) - k_2X_a(t) &= 0\\
      k_1S(t)X_T - k_1S(t)X_a(t) - k_2X_a(t) &= 0\\
      (k_1S(t) - k_2)X_a(t) &= k_1S(t)X_T\\
      X_a(t) &= \frac{k_1S(t)X_T}{k_1S(t) - k_2}\\
    \end{align*}

    \subsection{Adapted response}
    There are several physiological systems tthat give a constant response, independent of the strength of the signal.
    The ODEs are:

    $$\begin{cases}
      \frac{dX(t)}{dt} &= k_{0_1} + k_1S(t) - k_2X(t)Y(t)\\
      \frac{dY(t)}{dt} &= k_{0_2} + k_3S(t) - k_4Y(t)\\
    \end{cases}$$

    Assuming that in the absence of $S$ there is no production:

    $$\begin{cases}
      \frac{dX(t)}{dt} &= k_1S(t) - k_2X(t)Y(t)\\
      \frac{dY(t)}{dt} &= k_3S(t) - k_4Y(t)\\
    \end{cases}$$

    The response is the concentration at equilibrium:

    \begin{align*}
      \begin{cases}
        k_1S(t) - k_2X(t)Y(t) &= 0\\
        k_3S(t) - k_4Y(t) &= 0\\
      \end{cases}\\
      \begin{cases}
        k_2X(t)Y(t) &= k_1S(t)\\
        Y(t) &=\frac{k_3}{k_4}S(t)\\
      \end{cases}\\
      \begin{cases}
        k_2X(t)\frac{k_3}{k_4}\cancel{S(t)} &= k_1\cancel{S(t)}\\
        Y(t) &=\frac{k_3}{k_4}S(t)\\
      \end{cases}\\
      \begin{cases}
        X(t) &= \frac{k_1k_4}{k_2k_3}\\
        Y(t) &=\frac{k_3}{k_4}S(t)\\
      \end{cases}\\
    \end{align*}

    So the concentration of $X$ is independent o $S$: its response its independent of the signal if it is not null.
    In that case the system is:

    $$\begin{cases}
      \frac{dX(t)}{dt} &=  - k_2X(t)Y(t)\\
      \frac{dY(t)}{dt} &= - k_4Y(t)\\
    \end{cases}$$

    And at equilibrium:

    \begin{align*}
      \begin{cases}
         - k_2X(t)Y(t) &= 0\\
         - k_4Y(t) &= 0\\
      \end{cases}//
      \begin{cases}
         X(t) &= 0\\
         Y(t) &= 0\\
      \end{cases}//
    \end{align*}

    \subsubsection{Sigmoidal response}
    The activation and inactivation rates follow a Michaelis-Menten law.
    The production of a species is:

    $$\frac{dp(t)}{dt} = \frac{ms(t)}{s_h + s(t)}$$

    Considering this for an enzymatic production of $X_a$:

    $$\frac{dX_a(t)}{dt} = \frac{mX_i(t)}{X_{sh} + X_i(t)}$$

    There is $S$ as an activator and an opposite reaction that converts the active form into the inactive form:

    \begin{align*}
      \frac{dX_a(t)}{dt} &= \frac{m_1X_i(t)S(t)}{X_{ih} + X_i(t)} - \frac{m_2X_a(t)}{X_{ah} + X_a(t)}\\
                         &= \frac{m_1(X_T-X_a(t))S(t)}{X_{ih} +X_T - X_a(t)} - \frac{m_2X_a(t)}{X_{ah} + X_a(t)}\\
    \end{align*}

    Consiering the equilibrium:

    \begin{align*}
      \frac{m_1(X_T-X_a(t))S(t)}{X_{ih} +X_T - X_a(t)} - \frac{m_2X_a(t)}{X_{ah} + X_a(t)} &= 0
      \frac{m_1(X_T-X_a(t))S(t)}{X_{ih} +X_T - X_a(t)} &= \frac{m_2X_a(t)}{X_{ah} + X_a(t)}\\
    \end{align*}

    Introducing:

    $$X(t) = \frac{X_a}{X_T}\qquad C(t) = S(t)\frac{m_1}{m_2}\qquad L_1 = \frac{X_{ih}}{X_T}\qquad L_2 = \frac{X_{ah}}{X_T}$$

    The equation becomes:

    \begin{align*}
      \frac{m_1S(t)\cancel{X_T}(1-X(t))}{\cancel{X_T}(L_1 + 1 - X(t))} &= \frac{m_2\cancel{X_T}X(t)}{\cancel{X_T}(L_2 + X(t))}\\
      \frac{m_1S(t)(1-X(t))}{L_1 + 1 - X(t)} &= \frac{m_2X(t)}{L_2 + X(t)}\\
      \frac{\frac{m_1}{m_2}S(t)(1-X(t))}{L_1 + 1 - X(t)} &= \frac{X(t)}{L_2 + X(t)}\\
      \frac{C(t)(1-X(t))}{L_1+1-X(t)} &= \frac{X(t)}{L_2 + X(t)}\\
      C(t)(1-X(t))(L_2 + X(t)) - X(t)(L_1+1-X(t)) &= 0\\
    \end{align*}

    This will lead to a single biologically viable solution (a single equilibrium), in the form of a Goldbeter-Koshland function $x = f(x)$.
    Theay are a family of functions for which the shape canb e predicted by observing some of its parameters:

    \begin{multicols}{2}
      \begin{itemize}
        \item If $1+ L_1-L_1L_2 > 0$ the function is sigmoidal.
          The bigger the value, the more accentuated the sigmoidal behavior.
        \item If $1+ L_1-L_1L_2 < 0$ the function is a concave saturating function.
      \end{itemize}
    \end{multicols}

    It can be useful to write $C(t)$ as a function of $X(t)$: $C(X(T))$.
    Since $C$ is a function of $S$, it is equivalent to write $S(X)$:

    $$C(X) = \frac{X(T)(L_1+1-X(T))}{(1-X(t))(L_2+X(T))}$$

  \subsection{Feedback loops}

    \subsubsection{Positive feedback loop (switch with mutual inhibition)}
    Consider a feedback loope of positive type: $E$ decreases the concentration of $X$, while $X$ increases the concentration of $E$.
    Hence an increase in $X$ decrease the concentration of $E$.
    This decreases the decay rate of $X$, increasing its concentration.
    The set of ODE is:

    $$\begin{cases}
      \frac{dX(t)}{dt} &= k_0 + k_1S(t) - k_2X(t) - k'_2X(t)E(t)\\
      \frac{dE(t)}{dt} &= \frac{m_1e_p}{e_{ph} + e_p} - \frac{m_2E(t)X(t)}{e_h + E(t)}
    \end{cases}$$

    By setting $e_p = e_T-E(t)$:

    $$\begin{cases}
      \frac{dX(t)}{dt} &= k_0 + k_1S(t) - k_2X(t) - k'_2X(t)E(t)\\
      \frac{dE(t)}{dt} &= \frac{m_1(e_T-E(t))}{e_{ph} + e_T-E(t)} - \frac{m_2E(t)X(t)}{e_h + E(t)}
    \end{cases}$$

    To find the equilibrium point start with $X$:

    \begin{align*}
      k_0 + k_1S(t) - k_2X(t) - k'_2X(t)E(t) &= 0\\
      [k'_2E(t) + k_2]X(t) &= k_0 + k_1S(t)\\
      X(t) &= \frac{k_0 + k_1S(t)}{k'_2E(t) + k_2}
    \end{align*}

    Introducing $y(t) = \frac{E(t)}{e_T}$ this is a decreasing function of $y$:

    $$X(t) = f(y) = \frac{k_0 + k_1S(t)}{k'_2e_Ty(t) + k_2}$$

    Considering now the second equation:

    \begin{align*}
      \frac{m_1(e_T-E(t))}{e_{ph} + e_T-E(t)} - \frac{m_2E(t)X(t)}{e_h + E(t)} &= 0\\
      \frac{m_1(e_T-E(t))}{e_{ph} + e_T-E(t)} &= \frac{m_2E(t)X(t)}{e_h + E(t)}\\
    \end{align*}

    Considering:

    $$y(t) = \frac{E(t)}{e_T}\qquad c(t) = \frac{m_2}{m_1}X(t)\qquad L_1 = \frac{e_{ph}}{e_T}\qquad L_2=\frac{e_h}{e_T}$$

    Now solving:

    \begin{align*}
      \frac{m_1e_T(1-y(t))}{e_T(L_1 + 1-y(t))} &= \frac{m_2y(t)X(t)}{L_2 + y(t)}\\
      \frac{1-y}{L_1 + 1-y(t)} &= \frac{c(t)y(t)}{L_2 + y(t)}\\
    \end{align*}

    This is a Glodbeter Koshland function with $y = f(c)$, and since $c(t) = \frac{m_1}{m_2}x(t)$, the function is $y = f(x)$.
    This the goal is to find the equilibrium points, it is possible to compute the intersection of the first isocline and this one.
    First the second problem should be written as $x = f(y)$.

    \begin{align*}
      \frac{1-y(t)}{L_1 + 1-y(t)} &= \frac{c(t)y(t)}{L_2 + y(t)}\\
      c(t) = \frac{(1-y(t))(L_2 + y(t))}{y(t)(L_1 + 1-y(t))}\\
      \frac{m_2}{m_1}X(t) &= \frac{(1-y(t))(L_2 + y(t))}{y(t)(L_1 + 1-y(t))}\\
      X(t) &= \frac{m_1}{m_2}\frac{(1-y(t))(L_2 + y(t))}{y(t)(L_1 + 1-y(t))}\\
    \end{align*}

    The behavior of this equation can be inferred from $L_1$ and $L2$.
    Moreover, this function has flipped numerator and denominator with the term introduced previosly, so the inverse function has to be flipped.
    Finally:

    $$X(t) = f(t) = \frac{k_0 + k_1S(t)}{k_2+k'_2e_ty(t)}$$

    It is a decreasing function of $y$.
    Woth this $x(y)$ can be plotted for both functions.
    Thre equilibrium points are found.
    The central is unstable, while the other two are asymptotically stable if the GOldbeter Koshland is sigmoidal.
    If the Goldbeter Koshland is hyperbloic then ther eis only one equilibrium point.

    \subsubsection{Negative feedback loop}
    Mechanisms are at the basis of homeostasis.
    The associated ODEs are:

    $$\begin{cases}
      \frac{dx(t)}{dt} = k_0 + k_1s(t) - k_2x(t) - k_3x(e_T-x(t))\\
      \frac{de(t)}{dt} = \frac{m_1e_px(t)}{a + e_p} - \frac{m_2e(t)}{b+e(t)}
    \end{cases}$$

    Setting $e_T = e(t) + e_p$, so that $e_p = e_t-e(t)$:

    $$\begin{cases}
      \frac{dx(t)}{dt} = k_0 + k_1s(t) - k_2x(t) - k_3x(t)e(t)\\
      \frac{de(t)}{dt} = \frac{m_1(e_T-e(t))x(t)}{a + e_T-e(t)} - \frac{m_2e(t)}{b+e(t)}
    \end{cases}$$

    Finding the equilbria:

    \begin{align*}
      k_0 + k_1s(t) - k_2x(t) - k_3x(t)e(t) &= 0\\
      (k_2+k_3e(t))x(t) &= k_0 + k_1s(t)\\
      x(t) &= \frac{k_0 + k_1s(t)}{k_2 + k_3e(t)}
    \end{align*}

    Introducing $y(t) = \frac{e(t)}{e_T}$, this is a decreasing function of $y$:

    $$x(t) = f(y) = \frac{k_0 + k_1s(t)}{k_2 + k_3e_Ty(t)}$$

    Considering the second equation introduce $y(t) = \frac{e(t)}{e_T}$, $L_1 = \frac{a}{e_T}$, $L_2 = \frac{b}{e_T}$, $c = \frac{m_1}{m_2}x(t)$:

    \begin{align*}
      \frac{m_1e_T(1-y(t))x(t)}{e_T(L_1+1-y(t))} &= \frac{m_2e_Ty(t)}{e_T(L_2+y(t))}\\
      \frac{m_1(1-y(t))x(t)}{L_1+1-y(t)} &= \frac{m_2y(t)}{L_2+y(t)}\\
      \frac{c(t)(1-y(t))}{L_1 + 1-y(t)} &= \frac{y(t)}{L_2 + y(t)}\\
    \end{align*}

    This leads to a second degree equation for $y$, which lieads to a single viable solution in the form of a Goldbeter Koshland function $y(t) = f(c) = f(x)$.
    Its shape will be predicted from $L_1$ and $L_2$>
    Both isoclines are expressed as a function of the same variable.
    The first:

    $$x = f(y) = \frac{k_0 + k_1s(t)}{k_2 + k_3e_Ty}$$

    For the second:

    \begin{align*}
      x(1-y) &= \frac{y(L_1+1-y)}{L_2+y}\\
      c &= \frac{y(L_1+1-y)}{(1-y)(L_2+y)}\\
      x &= f(y) = \frac{y(L_1 + 1-y)}{(1-y)(L_2+y)\frac{m_1}{m_2}}\\
    \end{align*}

    Solving this the inverso of the Goldbeter KOshland function are obtained.
    In the case of a negative feedback loop, there is a single equilibrium which is always asymptotically stable.
    After perturbations, the system is taken back to the equilibrium.

    \subsubsection{Multiple negative feedback loop}
    Consider the set of ODE:

    $$\begin{cases}
      \frac{dx(t)}{dt} &= k_0 + k_1s -k_2x(t) - k_3x(t)y_p(t)\\
      \frac{de(t)}{dt} &= \frac{m_1e_px(t)}{a = e_p} - \frac{m_2e(t)}{b + e(t)}\\
      \frac{y_p(t)}{dt} &= \frac{m_3y(t)e(t)}{x+y(t)} - \frac{m_4y_p(t)}{c+y_p(t)}
    \end{cases}$$

    Looking for the equilibria:

    $$x(t) = \frac{k_0 + k_1s}{k_2 + k_3y_p(t)}$$

    Introducing $v(t) = \frac{y_p(t)}{y_T}$, it is a decreasing function of $v$:

    $$x = f(v) = \frac{k_0 + k_1s}{k_2 + k_3y_Tv(t)}$$

    For the second equation let $z(t) = \frac{e(t)}{e_T}$, $L_1 = \frac{a}{e_T}$, $L_2 = \frac{b}{e_T}$ and $c(t) = \frac{m_1}{m_2}x(t)$ and $e_p(t) = e_T- e(t)$:

    \begin{align*}
      \frac{m_1e_px(t)}{a + e_p} - \frac{m_2e(t)}{b + e(t)} &= 0\\
      \frac{m_1(e_T-e(t))x(t)}{a + (e_T-e(t))} - \frac{m_2e(t)}{b + e(t)} &= 0\\
      \frac{m_1e_T(1-z(t))x(t)}{e_T(L_1+1-z(t))} &= \frac{m_2e_Tz(t)}{e_T(L_2 + z(t))}\\
      \frac{m_1(1-z(t))x(t)}{L_1 + 1-z(t)} &= \frac{m_2z(t)}{L_2 + z(t)}\\
      \frac{c(t)(1-z(t))}{L_1+1-z(t)} &= \frac{z(t)}{L_2 + z(t)}\\
    \end{align*}

    Solving this leads to a Goldbeter Koshland function $z = f(x)$.
    Rewriting the generating function isolating $x$:

    \begin{align*}
      c(t) &= x(t) \frac{m_1}{m_2} = \frac{z(t)(L_1+1-z(t))}{(1-z(t))(L_2+z(t))}\\
      x(t) &= \frac{z(t)(L_1+1-z(t))}{(1-z(t))(L_2+z(t))\frac{m_1}{m_2}}\\
    \end{align*}

    here numerator and denominator are not flipped with respect to what it was introduced, solving this will lead exactly to the inverse of the Goldbeter Koshland function.\\
    For the third equation with $y(t) = y_T-y_p(t)$, $v(t) = \frac{y_p(t)}{y_T}$, $L_3 = \frac{c}{y_T}$ and $L_4 = \frac{d}{y_T}$ and $c(t) = \frac{m_3}{m_4}e(t)$:

    \begin{align*}
      \frac{m_3y(t)e(t)}{c(t) + y(t)} - \frac{m_4y_p}{d + y_p(t)} &= 0\\
      \frac{m_3(y_T-y_p(t))e(t)}{c(t) + y_T-y_p(t)} &= \frac{m_4y_p(t)}{d + y_p(t)}\\
      \frac{m_3y_T(1-v(t))e(t)}{y_T(L_3+1-v(t))} &= \frac{m_4y_Tv(t)}{y_T(L_4 + v(t))}\\
      \frac{m_3(1-v(t))e(t)}{L_3+1-v(t)} &= \frac{m_4v(t)}{L_4 + v(t)}\\
      \frac{c(t)(1-v(t))}{L_3+1-v(t)} &= \frac{v(t)}{L_4 + v(t)}\\
    \end{align*}

    Considering that $e = f(v)$:

    \begin{align*}
      c &= \frac{m_3}{m_4}e(t) = \frac{v(t)(L_3+1-v(t))}{(1-v(t))(L_4+v(t))}\\
      e(t) &= \frac{v(t)(L_3+1-v(t))}{(1-v(t))(L_4+v(t))\frac{m_3}{m_4}}\\
    \end{align*}

    Numerator and denominator are not flipped and solving this will lead to the inverse of the Goldbeter Koshland function.\\
    Because of their shape the two inverses Goldbeter Koshland will be increasing functions, and at equilibrium:

    $$x = f(v)\qquad x = f(z)\qquad e = f(v)$$

    BUt $f(z)\to f(e)$ since $z = \frac{e}{e_T}$, so:

    $$x = f(v)\qquad x = f(e)\qquad e = f(v)$$

    Considering the composition of the last two $xx = f(e(v))$, which is $x= f(v0$.
    So only the function $x = f(v)$ will be considered and plotted represengin the equilibrium of the first equation oand $f(e(v))$ representing a composition of two function, both inverse of the GOldbeter Koshland is an increasing function, so also the composition is inraesing.
    The first function is decreeasing.
    So there will be a single equilibrium found, of stability dependant on parameter values.
















\end{document}
